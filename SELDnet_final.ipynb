{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SELDnet_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UXG6e2PquoqN",
        "4eAes1fEADwk",
        "VQ-X5gRG_lY3",
        "z1d5ODXo_0OU",
        "YgTsIgOHAmec",
        "-TlgXGWWF1Xa",
        "Md2QwkPE0m-q",
        "PVSkPne8764R"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXG6e2PquoqN",
        "colab_type": "text"
      },
      "source": [
        "#***Download and unzip Ansim***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUrWflPRudbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Populate datasets, use it only at the beginning\n",
        "\n",
        "\n",
        "#Create folders for models and datasets\n",
        "!mkdir \"/content/drive/My Drive/folder\"\n",
        "!mkdir \"/content/drive/My Drive/folder/base_folder_ansim\"\n",
        "!mkdir \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!mkdir \"/content/drive/My Drive/folder/models\"\n",
        "\n",
        "#Downloads\n",
        "\n",
        "#ANSIM\n",
        "#ov1\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov1_split1\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov1_split2\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov1_split3\"\n",
        "#ov2\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov2_split1\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov2_split2\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov2_split3\"\n",
        "#ov3\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov3_split1\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov3_split2\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237703/files/ov3_split3\"\n",
        "#RESIM\n",
        "#ov1\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov1_split1.zip\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov1_split2.zip\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov1_split3.zip\"\n",
        "#ov2\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov2_split1.zip\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov2_split2.zip\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov2_split3.zip\"\n",
        "#ov3\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov3_split1.zip\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov3_split2.zip\"\n",
        "!wget  -P \"/content/drive/My Drive/Datasets/\" \"https://zenodo.org/record/1237707/files/ov3_split3.zip\"\n",
        "\n",
        "#Unzip datasets splits\n",
        "\n",
        "#ANSIM\n",
        "#ov1\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov1_split1.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov1_split2.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov1_split3.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "#ov2\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov2_split1.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov2_split2.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov2_split3.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "#ov3\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov3_split1.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov3_split2.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/ansim/ov3_split3.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "#RESIM\n",
        "#ov1\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov1_split1.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov1_split2.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov1_split3.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "#ov2\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov2_split1.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov2_split2.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov2_split3.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "#ov3\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov3_split1.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov3_split2.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\"\n",
        "!unzip \"/content/drive/My Drive/Datasets/resim/ov3_split3.zip\" -d \"/content/drive/My Drive/folder/base_folder_resim\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0EkabEj_ah5",
        "colab_type": "text"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heKkVYhl_Yy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import random\n",
        "import scipy.io.wavfile as wav\n",
        "import matplotlib.pyplot as plot\n",
        "import matplotlib.gridspec as gridspec\n",
        "import librosa.display\n",
        "import keras\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython import embed\n",
        "from collections import deque\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.layers import Bidirectional, Conv2D, MaxPooling2D, Input, MaxPooling3D, Conv3D, merge\n",
        "from keras.layers.core import Dense, Activation, Dropout, Reshape, Permute\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Tensorflow version %s\" %tf.__version__)\n",
        "print(\"sklearn version %s\" %sklearn.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Lkxc3TGf2C",
        "colab_type": "text"
      },
      "source": [
        "#***Parameters***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii9Oxnl2Giac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QUICK_TEST = True\n",
        "argv = '2'\n",
        "\n",
        "# ########### default parameters ##############\n",
        "params = dict(\n",
        "    drive_folder=\"/content/drive/My Drive/folder/\",\n",
        "    _output=True,     # If true, dumps the results recording-wise in 'dcase_dir' path.\n",
        "                           # Set this true after you have finalized your model, save the output, and submit\n",
        "    quick_test=QUICK_TEST,  # To do quick test. Trains/test on small subset of dataset\n",
        "    azi_only=False,      # Estimate Azimuth only\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # Dataset loading parameters\n",
        "    dataset='ansim',    # Dataset to use: ansim, resim, cansim, cresim, real, mansim or mreal\n",
        "    overlap=1,         # maximum number of overlapping sound events [1, 2, 3]\n",
        "    split=1,           # Cross validation split [1, 2, 3]\n",
        "    db=30,             # SNR of sound events.\n",
        "    nfft=512,          # FFT/window length size\n",
        "\n",
        "    # DNN Model parameters\n",
        "    sequence_length= None ,        # Feature sequence length\n",
        "    batch_size=16,              # Batch size\n",
        "    dropout_rate=0.0,           # Dropout rate, constant for all layers\n",
        "    nb_cnn2d_filt=64,           # Number of CNN nodes, constant for each layer\n",
        "    pool_size=[8, 8, 2],        # CNN pooling, length of list = number of CNN layers, list value = pooling per layer\n",
        "    rnn_size=[128, 128],        # RNN contents, length of list = number of layers, list value = number of nodes\n",
        "    fnn_size=[128],             # FNN contents, length of list = number of layers, list value = number of nodes\n",
        "    loss_weights=[1., 50.],     # [sed, doa] weight for scaling the DNN outputs\n",
        "    xyz_def_zero=True,          # Use default DOA Cartesian value x,y,z = 0,0,0\n",
        "    nb_epochs=200,             # Train for maximum epochs\n",
        "\n",
        "    # Not important\n",
        "    mode='regr',        # Only regression ('regr') supported as of now\n",
        "    nb_cnn3d_filt=32,   # For future. Not relevant for now\n",
        "    cnn_3d=False,       # For future. Not relevant for now\n",
        "    weakness=0          # For future. Not relevant for now\n",
        ")\n",
        "\n",
        "meta_params = dict(\n",
        "    name= params['dataset'] + '_ov' + str(params['overlap']) + '_sp' + str(params['split']) + \"xyz\" + \"quick\",\n",
        "    base_dir = params['drive_folder'] + 'base_folder_{}/'.format(params['dataset']),\n",
        "    model_dir = params['drive_folder'] + 'models/',   # Dumps the trained models and training curves in this folder\n",
        "    results_dir = params['drive_folder'] + 'results/',  # Dumps the recording-wise network output in this folder\n",
        "    plot_dir = params['drive_folder'] + 'plots/',\n",
        "    patience = int(0.05 * params['nb_epochs']),     # Stop training if patience reached\n",
        "    sequence_length = 512 if params['dataset'] == 'ansim' else 256\n",
        ")\n",
        "\"\"\"\n",
        "params['patience'] = int(0.05 * params['nb_epochs'])     # Stop training if patience reached\n",
        "params['sequence_length'] = 512 if params['dataset'] == 'ansim' else 256\n",
        "\"\"\"\n",
        "\n",
        "for key, value in params.items():\n",
        "    print(\"{}: {}\".format(key, value))\n",
        "\n",
        "\n",
        "def create_folder(folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        print('{} folder does not exist, creating it.'.format(folder_name))\n",
        "        os.makedirs(folder_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eAes1fEADwk",
        "colab_type": "text"
      },
      "source": [
        "#***Feature class***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJROoibMAKc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Contains routines for labels creation, features extraction and normalization\n",
        "#\n",
        "\n",
        "plot.switch_backend('agg')\n",
        "\n",
        "\n",
        "class FeatureClass:\n",
        "    def __init__(self, dataset='ansim', ov=1, split=1, nfft=1024, db=30, wav_extra_name='', desc_extra_name=''):\n",
        "\n",
        "        # Dataset folder: change meta_params selecting the dataset and the split f\n",
        "        self._base_folder = meta_params['base_dir']\n",
        "\n",
        "        # Input directories\n",
        "        self._aud_dir = os.path.join(self._base_folder, 'wav_ov{}_split{}_{}db{}'.format(ov, split, db, wav_extra_name))\n",
        "        self._desc_dir = os.path.join(self._base_folder, 'desc_ov{}_split{}{}'.format(ov, split, desc_extra_name))\n",
        "\n",
        "        # Output directories\n",
        "        self._label_dir = None\n",
        "        self._feat_dir = None\n",
        "        self._feat_dir_norm = None\n",
        "\n",
        "        # Local parameters\n",
        "        self._mode = None\n",
        "        self._ov = ov\n",
        "        self._split = split\n",
        "        self._db = db\n",
        "        self._nfft = nfft\n",
        "        self._win_len = self._nfft\n",
        "        self._hop_len = self._nfft/2\n",
        "        self._dataset = dataset\n",
        "        self._eps = np.spacing(np.float(1e-16))\n",
        "\n",
        "        # If circular-array 8 channels else 4 for Ambisonic\n",
        "        if 'c' in self._dataset:\n",
        "            self._nb_channels = 8\n",
        "        else:\n",
        "            self._nb_channels = 4\n",
        "\n",
        "        # Sound event classes dictionary\n",
        "        self._unique_classes = dict()\n",
        "        self._unique_classes = \\\n",
        "            {\n",
        "                'clearthroat': 2,\n",
        "                'cough': 8,\n",
        "                'doorslam': 9,\n",
        "                'drawer': 1,\n",
        "                'keyboard': 6,\n",
        "                'keysDrop': 4,\n",
        "                'knock': 0,\n",
        "                'laughter': 10,\n",
        "                'pageturn': 7,\n",
        "                'phone': 3,\n",
        "                'speech': 5\n",
        "            }\n",
        "\n",
        "        self._fs = 44100\n",
        "        self._frame_res = self._fs / float(self._hop_len)\n",
        "        self._hop_len_s = self._nfft/2.0/self._fs\n",
        "        self._nb_frames_1s = int(1 / self._hop_len_s)\n",
        "        self._fade_win_size = 0.01 * self._fs\n",
        "\n",
        "        self._resolution = 10\n",
        "        self._azi_list = range(-180, 180, self._resolution)\n",
        "        self._length = len(self._azi_list)\n",
        "        self._ele_list = range(-60, 60, self._resolution)\n",
        "        self._height = len(self._ele_list)\n",
        "        self._weakness = None\n",
        "\n",
        "        # For regression task only\n",
        "        self._default_azi = 180\n",
        "        self._default_ele = 60\n",
        "\n",
        "        if self._default_azi in self._azi_list:\n",
        "            print('ERROR: chosen default_azi value {} should not exist in azi_list'.format(self._default_azi))\n",
        "            exit()\n",
        "        if self._default_ele in self._ele_list:\n",
        "            print('ERROR: chosen default_ele value {} should not exist in ele_list'.format(self._default_ele))\n",
        "            exit()\n",
        "\n",
        "        self._audio_max_len_samples = 30 * self._fs\n",
        "\n",
        "        self._max_frames = int(np.ceil((self._audio_max_len_samples - self._win_len) / float(self._hop_len)))\n",
        "\n",
        "    def _load_audio(self, audio_path):\n",
        "        fs, audio = wav.read(audio_path)\n",
        "        audio = audio[:, :self._nb_channels] / 32768.0 + self._eps\n",
        "        if audio.shape[0] < self._audio_max_len_samples:\n",
        "            zero_pad = np.zeros((self._audio_max_len_samples - audio.shape[0], audio.shape[1]))\n",
        "            audio = np.vstack((audio, zero_pad))\n",
        "        elif audio.shape[0] > self._audio_max_len_samples:\n",
        "            audio = audio[:self._audio_max_len_samples, :]\n",
        "        return audio, fs\n",
        "\n",
        "    # INPUT FEATURES\n",
        "    @staticmethod\n",
        "    def _next_greater_power_of_2(x):\n",
        "        return 2 ** (x - 1).bit_length()\n",
        "\n",
        "    def _spectrogram(self, audio_input):\n",
        "        _nb_ch = audio_input.shape[1]\n",
        "        hann_win = np.repeat(np.hanning(self._win_len)[np.newaxis].T, _nb_ch, 1)\n",
        "        nb_bins = self._nfft // 2\n",
        "        spectra = np.zeros((self._max_frames, nb_bins, _nb_ch), dtype=complex)\n",
        "        for ind in range(self._max_frames):\n",
        "            start_ind = int(ind * self._hop_len)\n",
        "            aud_frame = audio_input[start_ind + np.arange(0, self._win_len), :] * hann_win\n",
        "            spectra[ind] = np.fft.fft(aud_frame, n=self._nfft, axis=0, norm='ortho')[:nb_bins, :]\n",
        "        return spectra\n",
        "\n",
        "    def _extract_spectrogram_for_file(self, audio_filename):\n",
        "        audio_in, fs = self._load_audio(os.path.join(self._aud_dir, audio_filename))\n",
        "        audio_spec = self._spectrogram(audio_in)\n",
        "        print(audio_spec.shape)\n",
        "        np.save(os.path.join(self._feat_dir, audio_filename), audio_spec.reshape(self._max_frames, -1))\n",
        "\n",
        "    # OUTPUT LABELS\n",
        "    def _read_desc_file(self, desc_filename, norm=False):\n",
        "        desc_file = {\n",
        "            'class': list(), 'start': list(), 'end': list(), 'ele': list(), 'azi': list(),\n",
        "            'ele_dir': list(), 'azi_dir': list(), 'ang_vel': list(), 'dist': list()\n",
        "        }\n",
        "        fid = open(os.path.join(self._desc_dir, desc_filename), 'r')\n",
        "        fid.readline()\n",
        "        for line in fid:\n",
        "            split_line = line.strip().split(',')\n",
        "            if 'real' in self._dataset:\n",
        "                desc_file['class'].append(split_line[0].split('.')[0].split('-')[1])\n",
        "            else:\n",
        "                desc_file['class'].append(split_line[0].split('.')[0][:-3])\n",
        "            if(norm):\n",
        "                norm_param_x = 3.45\n",
        "                norm_param_doa = 4\n",
        "                desc_file['start'].append(float(split_line[1])*norm_param_x)\n",
        "                desc_file['end'].append(float(split_line[2])*norm_param_x)\n",
        "            else:\n",
        "                desc_file['start'].append(int(np.floor(float(split_line[1])*self._frame_res)))\n",
        "                desc_file['end'].append(int(np.ceil(float(split_line[2])*self._frame_res)))\n",
        "            desc_file['ele'].append(int(float(split_line[3])))\n",
        "            desc_file['azi'].append(int(float(split_line[4])))\n",
        "            if self._dataset[0] is 'm':\n",
        "                if 'real' in self._dataset:\n",
        "                    desc_file['ang_vel'].append(int(float(split_line[5])))\n",
        "                    desc_file['dist'].append(float(split_line[6]))\n",
        "                else:\n",
        "                    desc_file['ele_dir'].append(int(float(split_line[5])))\n",
        "                    desc_file['azi_dir'].append(int(float(split_line[6])))\n",
        "                    desc_file['ang_vel'].append(int(float(split_line[7])))\n",
        "                    desc_file['dist'].append(float(split_line[8]))\n",
        "            else:\n",
        "                desc_file['dist'].append(float(split_line[5]))\n",
        "        fid.close()\n",
        "        return desc_file\n",
        "    \n",
        "    def get_list_index(self, azi, ele):\n",
        "        azi = (azi - self._azi_list[0]) // 10\n",
        "        ele = (ele - self._ele_list[0]) // 10\n",
        "        return azi * self._height + ele\n",
        "\n",
        "    def _get_matrix_index(self, ind):\n",
        "        azi, ele = ind // self._height, ind % self._height\n",
        "        azi = (azi * 10 + self._azi_list[0])\n",
        "        ele = (ele * 10 + self._ele_list[0])\n",
        "        return azi, ele\n",
        "\n",
        "    def get_vector_index(self, ind):\n",
        "        azi = (ind * 10 + self._azi_list[0])\n",
        "        return azi\n",
        "\n",
        "    @staticmethod\n",
        "    def scaled_cross_product(a, b):\n",
        "        ab = np.dot(a, b)\n",
        "        if ab > 1 or ab < -1:\n",
        "            return [999]\n",
        "\n",
        "        acos_ab = np.arccos(ab)\n",
        "        x = np.cross(a, b)\n",
        "        if acos_ab == np.pi or acos_ab == 0 or sum(x) == 0:\n",
        "            return [999]\n",
        "        else:\n",
        "            return x/np.sqrt(np.sum(x**2))\n",
        "\n",
        "    def get_trajectory(self, event_length_s, _start_xyz, _rot_vec, _random_ang_vel):\n",
        "        frames_per_sec = self._fs / self._fade_win_size\n",
        "        ang_vel_per_win = _random_ang_vel / frames_per_sec\n",
        "        nb_frames = int(np.ceil(event_length_s * frames_per_sec))\n",
        "        xyz_array = np.zeros((nb_frames, 3))\n",
        "        for frame in range(nb_frames):\n",
        "            _R = self.rotate_matrix_vec_ang(_rot_vec, frame * ang_vel_per_win)\n",
        "            xyz_array[frame, :] = np.dot(_start_xyz, _R.T)\n",
        "        return xyz_array\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def rotate_matrix_vec_ang(_rot_vec, theta):\n",
        "        u_x_u = np.array(\n",
        "            [\n",
        "                [_rot_vec[0] ** 2, _rot_vec[0] * _rot_vec[1], _rot_vec[0] * _rot_vec[2]],\n",
        "                [_rot_vec[1] * _rot_vec[0], _rot_vec[1] ** 2, _rot_vec[1] * _rot_vec[2]],\n",
        "                [_rot_vec[2] * _rot_vec[0], _rot_vec[2] * _rot_vec[1], _rot_vec[2] ** 2]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        u_x = np.array(\n",
        "            [\n",
        "                [0, -_rot_vec[2], _rot_vec[1]],\n",
        "                [_rot_vec[2], 0, -_rot_vec[0]],\n",
        "                [-_rot_vec[1], _rot_vec[0], 0]\n",
        "            ]\n",
        "        )\n",
        "        return np.eye(3) * np.cos(theta) + np.sin(theta) * u_x + (1 - np.cos(theta)) * u_x_u\n",
        "\n",
        "    @staticmethod\n",
        "    def sph2cart(az, el, r):\n",
        "        \"\"\"\n",
        "        Converts spherical coordinates given by azimuthal, elevation and radius to cartesian coordinates of x, y and z\n",
        "\n",
        "        :param az: azimuth angle\n",
        "        :param el: elevation angle\n",
        "        :param r: radius\n",
        "        :return: cartesian coordinate\n",
        "        \"\"\"\n",
        "        rcos_theta = r * np.cos(el)\n",
        "        x = rcos_theta * np.cos(az)\n",
        "        y = rcos_theta * np.sin(az)\n",
        "        z = r * np.sin(el)\n",
        "        return x, y, z\n",
        "\n",
        "    @staticmethod\n",
        "    def cart2sph(x, y, z):\n",
        "        XsqPlusYsq = x ** 2 + y ** 2\n",
        "        r = np.sqrt(XsqPlusYsq + z ** 2)  # r\n",
        "        elev = np.arctan2(z, np.sqrt(XsqPlusYsq))  # theta\n",
        "        az = np.arctan2(y, x)  # phi\n",
        "        return az, elev, r\n",
        "\n",
        "    @staticmethod\n",
        "    def wrapToPi(rad_list):\n",
        "        xwrap = np.remainder(rad_list, 2 * np.pi)\n",
        "        mask = np.abs(xwrap) > np.pi\n",
        "        xwrap[mask] -= 2 * np.pi * np.sign(xwrap[mask])\n",
        "        return xwrap\n",
        "\n",
        "    def wrapTo180(self, deg_list):\n",
        "        rad_list = deg_list * np.pi / 180.\n",
        "        rad_list = self.wrapToPi(rad_list)\n",
        "        deg_list = rad_list * 180 / np.pi\n",
        "        return deg_list\n",
        "\n",
        "    def _get_doa_labels_regr(self, _desc_file):\n",
        "        azi_label = self._default_azi*np.ones((self._max_frames, len(self._unique_classes)))\n",
        "        ele_label = self._default_ele*np.ones((self._max_frames, len(self._unique_classes)))\n",
        "        for i, ele_ang in enumerate(_desc_file['ele']):\n",
        "            start_frame = _desc_file['start'][i]\n",
        "            if start_frame > self._max_frames:\n",
        "                continue\n",
        "            end_frame = self._max_frames if _desc_file['end'][i] > self._max_frames else _desc_file['end'][i]\n",
        "            nb_frames = end_frame - start_frame\n",
        "            azi_ang = _desc_file['azi'][i]\n",
        "            class_ind = self._unique_classes[_desc_file['class'][i]]\n",
        "            if self._dataset[0] is 'm':\n",
        "                if 'real' in self._dataset:\n",
        "                    se_len_s = nb_frames / self._frame_res\n",
        "                    azi_trajectory = np.floor(\n",
        "                        np.linspace(azi_ang, azi_ang+_desc_file['ang_vel'][i]*se_len_s, nb_frames)\n",
        "                    )\n",
        "                    azi_ang = self.wrapTo180(azi_trajectory)\n",
        "\n",
        "                else:\n",
        "                    start_xyz = self.sph2cart(azi_ang*np.pi/180, ele_ang*np.pi/180, 1)\n",
        "                    direction_xyz = self.sph2cart(_desc_file['azi_dir'][i]*np.pi/180, _desc_file['ele_dir'][i]*np.pi/180, 1)\n",
        "\n",
        "                    rot_vec = self.scaled_cross_product(start_xyz, direction_xyz)\n",
        "                    xyz_trajectory = self.get_trajectory(\n",
        "                        nb_frames/self._frame_res, start_xyz, rot_vec, _desc_file['ang_vel'][i]*np.pi/180)\n",
        "\n",
        "                    tmp_azi_ang, tmp_ele_ang, tmp_r = self.cart2sph(\n",
        "                        xyz_trajectory[:, 0], xyz_trajectory[:, 1], xyz_trajectory[:, 2])\n",
        "                    org_time = np.linspace(0, 1, tmp_azi_ang.shape[0])\n",
        "                    new_time = np.linspace(0, 1, end_frame - start_frame)\n",
        "                    azi_ang = np.interp(new_time, org_time, tmp_azi_ang * 180/np.pi)\n",
        "                    ele_ang = np.interp(new_time, org_time, tmp_ele_ang * 180/np.pi)\n",
        "\n",
        "            if np.sum(ele_ang >= self._ele_list[0]) and np.sum(ele_ang <= self._ele_list[-1]):\n",
        "                azi_label[start_frame:end_frame, class_ind] = azi_ang\n",
        "                ele_label[start_frame:end_frame, class_ind] = ele_ang\n",
        "            else:\n",
        "                print('bad_angle {} {}'.format(azi_ang, ele_ang))\n",
        "        doa_label_regr = np.concatenate((azi_label, ele_label), axis=1)\n",
        "        return doa_label_regr\n",
        "\n",
        "    def _get_se_labels(self, _desc_file):\n",
        "        se_label = np.zeros((self._max_frames, len(self._unique_classes)))\n",
        "        for i, se_class in enumerate(_desc_file['class']):\n",
        "            start_frame = _desc_file['start'][i]\n",
        "            end_frame = self._max_frames if _desc_file['end'][i] > self._max_frames else _desc_file['end'][i]\n",
        "            se_label[start_frame:end_frame + 1, self._unique_classes[se_class]] = 1\n",
        "        return se_label\n",
        "\n",
        "\n",
        "    def _get_labels_for_file(self, label_filename, _desc_file):\n",
        "        label_mat = None\n",
        "        if self._mode is 'regr':\n",
        "            se_label = self._get_se_labels(_desc_file)\n",
        "            doa_label = self._get_doa_labels_regr(_desc_file)\n",
        "            label_mat = np.concatenate((se_label, doa_label), axis=1)\n",
        "        else:\n",
        "            print(\"The supported modes are 'regr', you provided {}\".format(self._mode))\n",
        "        print(label_mat.shape)\n",
        "        np.save(os.path.join(self._label_dir, label_filename), label_mat)\n",
        "\n",
        "    def get_clas_labels_for_file(self, _desc_file):\n",
        "        \"\"\"\n",
        "        Reads description file and returns classification format labels for SELD\n",
        "        :param _desc_file: csv file\n",
        "        :return: _labels: matrix of SELD labels of dimension [nb_frames, nb_classes, nb_azi*nb_ele],\n",
        "                          which is 1 for active sound event and location else zero\n",
        "        \"\"\"\n",
        "\n",
        "        _labels = np.zeros((self._max_frames, len(self._unique_classes), len(self._azi_list) * len(self._ele_list)))\n",
        "        for _ind, _start_frame in enumerate(_desc_file['start']):\n",
        "            _tmp_class = self._unique_classes[_desc_file['class'][_ind]]\n",
        "            _tmp_azi = _desc_file['azi'][_ind]\n",
        "            _tmp_ele = _desc_file['ele'][_ind]\n",
        "            _tmp_end = self._max_frames if _desc_file['end'][_ind] > self._max_frames else _desc_file['end'][_ind]\n",
        "            _tmp_ind = self.get_list_index(_tmp_azi, _tmp_ele)\n",
        "            _labels[_start_frame:_tmp_end + 1, _tmp_class, _tmp_ind] = 1\n",
        "\n",
        "        return _labels\n",
        "\n",
        "    # ------------------------------- EXTRACT FEATURE AND PREPROCESS IT -------------------------------\n",
        "    def extract_all_feature(self, extra=''):\n",
        "        # setting up folders\n",
        "        self._feat_dir = self.get_unnormalized_feat_dir(extra)\n",
        "        create_folder(self._feat_dir)\n",
        "\n",
        "        # extraction starts\n",
        "        print('Extracting spectrogram:')\n",
        "        print('\\t\\taud_dir {}\\n\\t\\tdesc_dir {}\\n\\t\\tfeat_dir {}'.format(\n",
        "            self._aud_dir, self._desc_dir, self._feat_dir))\n",
        "\n",
        "        for file_cnt, file_name in enumerate(os.listdir(self._desc_dir)):\n",
        "            print('file_cnt {}, file_name {}'.format(file_cnt, file_name))\n",
        "            wav_filename = '{}.wav'.format(file_name.split('.')[0])\n",
        "            self._extract_spectrogram_for_file(wav_filename)\n",
        "\n",
        "    def preprocess_features(self, extra=''):\n",
        "        # Setting up folders and filenames\n",
        "        self._feat_dir = self.get_unnormalized_feat_dir(extra)\n",
        "        self._feat_dir_norm = self.get_normalized_feat_dir(extra)\n",
        "        create_folder(self._feat_dir_norm)\n",
        "        normalized_features_wts_file = self.get_normalized_wts_file(extra)\n",
        "\n",
        "        # pre-processing starts\n",
        "        print('Estimating weights for normalizing feature files:')\n",
        "        print('\\t\\tfeat_dir {}'.format(self._feat_dir))\n",
        "\n",
        "        spec_scaler = preprocessing.StandardScaler()\n",
        "        train_cnt = 0\n",
        "        for file_cnt, file_name in enumerate(os.listdir(self._feat_dir)):\n",
        "            if 'train' in file_name:\n",
        "                print(file_cnt, train_cnt, file_name)\n",
        "                feat_file = np.load(os.path.join(self._feat_dir, file_name))\n",
        "                spec_scaler.partial_fit(np.concatenate((np.abs(feat_file), np.angle(feat_file)), axis=1))\n",
        "                del feat_file\n",
        "                train_cnt += 1\n",
        "        joblib.dump(\n",
        "            spec_scaler,\n",
        "            normalized_features_wts_file\n",
        "        )\n",
        "\n",
        "        print('Normalizing feature files:')\n",
        "        for file_cnt, file_name in enumerate(os.listdir(self._feat_dir)):\n",
        "                print(file_cnt, file_name)\n",
        "                feat_file = np.load(os.path.join(self._feat_dir, file_name))\n",
        "                feat_file = spec_scaler.transform(np.concatenate((np.abs(feat_file), np.angle(feat_file)), axis=1))\n",
        "                np.save(\n",
        "                    os.path.join(self._feat_dir_norm, file_name),\n",
        "                    feat_file\n",
        "                )\n",
        "                del feat_file\n",
        "        print('normalized files written to {} folder and the scaler to {}'.format(\n",
        "            self._feat_dir_norm, normalized_features_wts_file))\n",
        "\n",
        "    def normalize_features(self, extraname=''):\n",
        "        # Setting up folders and filenames\n",
        "        self._feat_dir = self.get_unnormalized_feat_dir(extraname)\n",
        "        self._feat_dir_norm = self.get_normalized_feat_dir(extraname)\n",
        "        create_folder(self._feat_dir_norm)\n",
        "        normalized_features_wts_file = self.get_normalized_wts_file()\n",
        "\n",
        "        # pre-processing starts\n",
        "        print('Estimating weights for normalizing feature files:')\n",
        "        print('\\t\\tfeat_dir {}'.format(self._feat_dir))\n",
        "\n",
        "        spec_scaler = joblib.load(normalized_features_wts_file)\n",
        "        print('Normalizing feature files:')\n",
        "        for file_cnt, file_name in enumerate(os.listdir(self._feat_dir)):\n",
        "                print(file_cnt, file_name)\n",
        "                feat_file = np.load(os.path.join(self._feat_dir, file_name))\n",
        "                feat_file = spec_scaler.transform(np.concatenate((np.abs(feat_file), np.angle(feat_file)), axis=1))\n",
        "                np.save(\n",
        "                    os.path.join(self._feat_dir_norm, file_name),\n",
        "                    feat_file\n",
        "                )\n",
        "                del feat_file\n",
        "        print('normalized files written to {} folder and the scaler to {}'.format(\n",
        "            self._feat_dir_norm, normalized_features_wts_file))\n",
        "\n",
        "    # ------------------------------- EXTRACT LABELS AND PREPROCESS IT -------------------------------\n",
        "    def extract_all_labels(self, mode='regr', weakness=0, extra=''):\n",
        "        self._label_dir = self.get_label_dir(mode, weakness, extra)\n",
        "        self._mode = mode\n",
        "        self._weakness = weakness\n",
        "\n",
        "        print('Extracting spectrogram and labels:')\n",
        "        print('\\t\\taud_dir {}\\n\\t\\tdesc_dir {}\\n\\t\\tlabel_dir {}'.format(\n",
        "            self._aud_dir, self._desc_dir, self._label_dir))\n",
        "        create_folder(self._label_dir)\n",
        "\n",
        "        for file_cnt, file_name in enumerate(os.listdir(self._desc_dir)):\n",
        "            print('file_cnt {}, file_name {}'.format(file_cnt, file_name))\n",
        "            wav_filename = '{}.wav'.format(file_name.split('.')[0])\n",
        "            desc_file = self._read_desc_file(file_name)\n",
        "            self._get_labels_for_file(wav_filename, desc_file)\n",
        "\n",
        "    # ------------------------------- Misc public functions -------------------------------\n",
        "    def get_classes(self):\n",
        "        return self._unique_classes\n",
        "\n",
        "    def get_normalized_feat_dir(self, extra=''):\n",
        "        return os.path.join(\n",
        "            self._base_folder,\n",
        "            'spec_ov{}_split{}_{}db_nfft{}{}_norm'.format(self._ov, self._split, self._db, self._nfft, extra)\n",
        "        )\n",
        "\n",
        "    def get_unnormalized_feat_dir(self, extra=''):\n",
        "        return os.path.join(\n",
        "            self._base_folder,\n",
        "            'spec_ov{}_split{}_{}db_nfft{}{}'.format(self._ov, self._split, self._db, self._nfft, extra)\n",
        "        )\n",
        "    \n",
        "    def get_matrix_index(self, ind):\n",
        "        azi, ele = ind // self._height, ind % self._height\n",
        "        azi = (azi * 10 + self._azi_list[0])\n",
        "        ele = (ele * 10 + self._ele_list[0])\n",
        "        return azi, ele\n",
        "\n",
        "    def get_label_dir(self, mode, weakness, extra=''):\n",
        "        return os.path.join(\n",
        "            self._base_folder,\n",
        "            'label_ov{}_split{}_nfft{}_{}{}{}'.format(self._ov, self._split, self._nfft, mode, 0 if mode is 'regr' else weakness, extra)\n",
        "        )\n",
        "\n",
        "    def get_normalized_wts_file(self, extra=''):\n",
        "        return os.path.join(\n",
        "            self._base_folder,\n",
        "            'spec_ov{}_split{}_{}db_nfft{}{}_wts'.format(self._ov, self._split, self._db, self._nfft, extra)\n",
        "        )\n",
        "\n",
        "    def get_default_azi_ele_regr(self):\n",
        "        return self._default_azi, self._default_ele\n",
        "\n",
        "    def get_nb_channels(self):\n",
        "        return self._nb_channels\n",
        "\n",
        "    def nb_frames_1s(self):\n",
        "        return self._nb_frames_1s\n",
        "\n",
        "    def get_hop_len_sec(self):\n",
        "        return self._hop_len_s\n",
        "\n",
        "    def get_azi_ele_list(self):\n",
        "        return self._azi_list, self._ele_list    \n",
        "\n",
        "    def get_nb_frames(self):\n",
        "        return self._max_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ-X5gRG_lY3",
        "colab_type": "text"
      },
      "source": [
        "#***Feature Extraction***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZANb0L5_G2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracts the features, labels, and normalizes the training and test split features. Make sure you update the location\n",
        "# of the downloaded datasets before in the Feature Class\n",
        "\n",
        "dataset_name = params['dataset']  # Datasets: ansim, resim, cansim, cresim, real, mansim and mreal\n",
        "\n",
        "# Extracts feature and labels for all overlap and splits\n",
        "for ovo in [1,2,3]:  # Overlap. Change to [1] if you are only calculating the features for overlap 1.\n",
        "    for splito in [1,2,3]:    # all splits. Change to [1] if you are only calculating features for split 1.\n",
        "        for nffto in [512]:\n",
        "            feat_cls = FeatureClass(ov=ovo, split=splito, nfft=nffto, dataset=dataset_name)\n",
        "\n",
        "            # Extract features and normalize them\n",
        "            feat_cls.extract_all_feature()\n",
        "            feat_cls.preprocess_features()\n",
        "\n",
        "            # # Extract labels in regression mode\n",
        "            feat_cls.extract_all_labels('regr', 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1d5ODXo_0OU",
        "colab_type": "text"
      },
      "source": [
        "#***Data Generator Class***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1avQEU6M_25m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Data generator for training the SELDnet\n",
        "#\n",
        "\n",
        "class DataGenerator(object):\n",
        "    def __init__(\n",
        "            self, datagen_mode='train', dataset='ansim', ov=1, split=1, db=30, batch_size=32, seq_len=64,\n",
        "            shuffle=True, nfft=512, classifier_mode='regr', weakness=0, cnn3d=False, xyz_def_zero=False, extra_name='',\n",
        "            azi_only=False\n",
        "    ):\n",
        "        self._datagen_mode = datagen_mode\n",
        "        self._classifier_mode = classifier_mode\n",
        "        self._batch_size = batch_size\n",
        "        self._seq_len = seq_len\n",
        "        self._shuffle = shuffle\n",
        "        self._feat_cls = FeatureClass(dataset=dataset, ov=ov, split=split, db=db, nfft=nfft)\n",
        "        self._label_dir = self._feat_cls.get_label_dir(classifier_mode, weakness, extra_name)\n",
        "        self._feat_dir = self._feat_cls.get_normalized_feat_dir(extra_name)\n",
        "        self._thickness = weakness\n",
        "        self._xyz_def_zero = xyz_def_zero\n",
        "        self._azi_only = azi_only\n",
        "\n",
        "        self._filenames_list = list()\n",
        "        self._nb_frames_file = None     # Assuming number of frames in feat files are the same\n",
        "        self._feat_len = None\n",
        "        self._2_nb_ch = 2 * self._feat_cls.get_nb_channels()\n",
        "        self._label_len = None  # total length of label - DOA + SED\n",
        "        self._doa_len = None    # DOA label length\n",
        "        self._class_dict = self._feat_cls.get_classes()\n",
        "        self._nb_classes = len(self._class_dict.keys())\n",
        "        self._default_azi, self._default_ele = self._feat_cls.get_default_azi_ele_regr()\n",
        "        self._is_cnn3d_model = cnn3d\n",
        "        self._get_label_filenames_sizes()\n",
        "\n",
        "        self._batch_seq_len = self._batch_size*self._seq_len\n",
        "        self._circ_buf_feat = None\n",
        "        self._circ_buf_label = None\n",
        "\n",
        "        self._nb_total_batches = int(np.floor((len(self._filenames_list) * self._nb_frames_file /\n",
        "                                               float(self._seq_len * self._batch_size))))\n",
        "\n",
        "        print(\n",
        "            'Datagen_mode: {}, nb_files: {}, nb_classes:{}\\n'\n",
        "            'nb_frames_file: {}, feat_len: {}, nb_ch: {}, label_len:{}\\n'.format(\n",
        "                self._datagen_mode, len(self._filenames_list),  self._nb_classes,\n",
        "                self._nb_frames_file, self._feat_len, self._2_nb_ch, self._label_len\n",
        "                )\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            'Dataset: {}, ov: {}, split: {}\\n'\n",
        "            'batch_size: {}, seq_len: {}, shuffle: {}\\n'\n",
        "            'label_dir: {}\\n '\n",
        "            'feat_dir: {}\\n'.format(\n",
        "                dataset, ov, split,\n",
        "                self._batch_size, self._seq_len, self._shuffle,\n",
        "                self._label_dir, self._feat_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def get_data_sizes(self):\n",
        "        feat_shape = (self._batch_size, self._2_nb_ch, self._seq_len, self._feat_len)\n",
        "        label_shape = [\n",
        "            (self._batch_size, self._seq_len, self._nb_classes),\n",
        "            (self._batch_size, self._seq_len, self._nb_classes*(2 if self._azi_only else 3))\n",
        "        ]\n",
        "        return feat_shape, label_shape\n",
        "\n",
        "    def get_total_batches_in_data(self):\n",
        "        return self._nb_total_batches\n",
        "\n",
        "    def _get_label_filenames_sizes(self):\n",
        "        for filename in os.listdir(self._label_dir):\n",
        "            if self._datagen_mode in filename:\n",
        "                self._filenames_list.append(filename)\n",
        "\n",
        "        temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[0]))\n",
        "        self._nb_frames_file = temp_feat.shape[0]\n",
        "        self._feat_len = temp_feat.shape[1] // self._2_nb_ch\n",
        "\n",
        "        temp_label = np.load(os.path.join(self._label_dir, self._filenames_list[0]))\n",
        "        self._label_len = temp_label.shape[-1]\n",
        "        self._doa_len = (self._label_len - self._nb_classes)/self._nb_classes\n",
        "        return\n",
        "\n",
        "    def generate(self):\n",
        "        \"\"\"\n",
        "        Generates batches of samples\n",
        "        :return: \n",
        "        \"\"\"\n",
        "\n",
        "        while 1:\n",
        "            if self._shuffle:\n",
        "                random.shuffle(self._filenames_list)\n",
        "\n",
        "            self._circ_buf_feat = deque()\n",
        "            self._circ_buf_label = deque()\n",
        "\n",
        "            file_cnt = 0\n",
        "\n",
        "            for i in range(self._nb_total_batches):\n",
        "\n",
        "                # load feat and label to circular buffer. Always maintain atleast one batch worth feat and label in the\n",
        "                # circular buffer. If not keep refilling it.\n",
        "                while len(self._circ_buf_feat) < self._batch_seq_len:\n",
        "                    temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[file_cnt]))\n",
        "                    temp_label = np.load(os.path.join(self._label_dir, self._filenames_list[file_cnt]))\n",
        "\n",
        "                    for row_cnt, row in enumerate(temp_feat):\n",
        "                        self._circ_buf_feat.append(row)\n",
        "                        self._circ_buf_label.append(temp_label[row_cnt])\n",
        "                    file_cnt = file_cnt + 1\n",
        "\n",
        "                # Read one batch size from the circular buffer\n",
        "                feat = np.zeros((self._batch_seq_len, self._feat_len * self._2_nb_ch))\n",
        "                label = np.zeros((self._batch_seq_len, self._label_len))\n",
        "                for j in range(self._batch_seq_len):\n",
        "                    if len(self._circ_buf_feat) == 0:\n",
        "                        break\n",
        "                    feat[j, :] = self._circ_buf_feat.popleft()\n",
        "                    label[j, :] = self._circ_buf_label.popleft()\n",
        "                feat = np.reshape(feat, (self._batch_seq_len, self._feat_len, self._2_nb_ch))\n",
        "                \n",
        "                # Split to sequences\n",
        "                feat = self._split_in_seqs(feat)\n",
        "                feat = np.transpose(feat, (0, 3, 1, 2))\n",
        "                label = self._split_in_seqs(label)\n",
        "                \n",
        "                if self._azi_only:\n",
        "                    # Get Cartesian coordinates from azi/ele\n",
        "                    azi_rad = label[:, :, self._nb_classes:2 * self._nb_classes] * np.pi / 180\n",
        "                    x = np.cos(azi_rad)\n",
        "                    y = np.sin(azi_rad)\n",
        "\n",
        "                    # Set default Cartesian x,y,z coordinates to 0,0,0\n",
        "                    if self._xyz_def_zero:\n",
        "                        no_ele_ind = np.where(label[:, :, 2 * self._nb_classes:] == self._default_ele)\n",
        "                        x[no_ele_ind] = 0\n",
        "                        y[no_ele_ind] = 0\n",
        "\n",
        "                    label = [\n",
        "                        label[:, :, :self._nb_classes],  # SED labels\n",
        "                        np.concatenate((x, y), -1)       # DOA Cartesian labels\n",
        "                    ]\n",
        "                else:\n",
        "                    # Get Cartesian coordinates from azi/ele\n",
        "                    azi_rad = label[:, :, self._nb_classes:2 * self._nb_classes] * np.pi / 180\n",
        "                    ele_rad = label[:, :, 2 * self._nb_classes:] * np.pi / 180\n",
        "                    tmp_label = np.cos(ele_rad)\n",
        "\n",
        "                    x = np.cos(azi_rad) * tmp_label\n",
        "                    y = np.sin(azi_rad) * tmp_label\n",
        "                    z = np.sin(ele_rad)\n",
        "\n",
        "                    # Set default Cartesian x,y,z coordinates to 0,0,0\n",
        "                    if self._xyz_def_zero:\n",
        "                        no_ele_ind = np.where(label[:, :, 2 * self._nb_classes:] == self._default_ele)\n",
        "                        x[no_ele_ind] = 0\n",
        "                        z[no_ele_ind] = 0\n",
        "                        y[no_ele_ind] = 0\n",
        "\n",
        "                    label = [\n",
        "                        label[:, :, :self._nb_classes],  # SED labels\n",
        "                        np.concatenate((x, y, z), -1)    # DOA Cartesian labels\n",
        "                         ]\n",
        "\n",
        "                yield feat, label  \n",
        "\n",
        "\n",
        "    def _split_in_seqs(self, data):\n",
        "        if len(data.shape) == 1:\n",
        "            if data.shape[0] % self._seq_len:\n",
        "                data = data[:-(data.shape[0] % self._seq_len), :]\n",
        "            data = data.reshape((data.shape[0] // self._seq_len, self._seq_len, 1))\n",
        "        elif len(data.shape) == 2:\n",
        "            if data.shape[0] % self._seq_len:\n",
        "                data = data[:-(data.shape[0] % self._seq_len), :]\n",
        "            data = data.reshape((data.shape[0] // self._seq_len, self._seq_len, data.shape[1]))\n",
        "        elif len(data.shape) == 3:\n",
        "            if data.shape[0] % self._seq_len:\n",
        "                data = data[:-(data.shape[0] % self._seq_len), :, :]\n",
        "            data = data.reshape((data.shape[0] // self._seq_len, self._seq_len, data.shape[1], data.shape[2]))\n",
        "        else:\n",
        "            print('ERROR: Unknown data dimensions: {}'.format(data.shape))\n",
        "            exit()\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def split_multi_channels(data, num_channels):\n",
        "        tmp = None\n",
        "        in_shape = data.shape\n",
        "        if len(in_shape) == 3:\n",
        "            hop = in_shape[2] / num_channels\n",
        "            tmp = np.zeros((in_shape[0], num_channels, in_shape[1], hop))\n",
        "            for i in range(num_channels):\n",
        "                tmp[:, i, :, :] = data[:, :, i * hop:(i + 1) * hop]\n",
        "        elif len(in_shape) == 4 and num_channels == 1:\n",
        "            tmp = np.zeros((in_shape[0], 1, in_shape[1], in_shape[2], in_shape[3]))\n",
        "            tmp[:, 0, :, :, :] = data\n",
        "        else:\n",
        "            print('ERROR: The input should be a 3D matrix but it seems to have dimensions: {}'.format(in_shape))\n",
        "            exit()\n",
        "        return tmp\n",
        "\n",
        "    def get_list_index(self, azi, ele):\n",
        "        return self._feat_cls.get_list_index(azi, ele)\n",
        "\n",
        "    def get_matrix_index(self, ind):\n",
        "        return np.array(self._feat_cls.get_vector_index(ind))\n",
        "\n",
        "    def get_nb_classes(self):\n",
        "        return self._nb_classes\n",
        "\n",
        "    def nb_frames_1s(self):\n",
        "        return self._feat_cls.nb_frames_1s()\n",
        "\n",
        "    def get_frame_per_file(self):\n",
        "        return self._batch_seq_len\n",
        "\n",
        "    def get_classes(self):\n",
        "        return self._feat_cls.get_classes()\n",
        "\n",
        "    def get_nb_frames(self):\n",
        "        return self._feat_cls._max_frames\n",
        "\n",
        "    def get_filelist(self):\n",
        "        return self._filenames_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgTsIgOHAmec",
        "colab_type": "text"
      },
      "source": [
        "#***Evaluation Metrics***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eeCxvbKFc4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Implements the core metrics from sound event detection evaluation module http://tut-arg.github.io/sed_eval/ and\n",
        "# the DOA metrics explained in the SELDnet paper\n",
        "#\n",
        "\n",
        "eps = np.finfo(np.float).eps\n",
        "\n",
        "###############################################################\n",
        "# Scoring functions\n",
        "###############################################################\n",
        "\n",
        "\n",
        "def reshape_3Dto2D(A):\n",
        "    return A.reshape(A.shape[0] * A.shape[1], A.shape[2])\n",
        "\n",
        "\n",
        "def f1_overall_framewise(O, T):\n",
        "    if len(O.shape) == 3:\n",
        "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "    TP = ((2 * T - O) == 1).sum()\n",
        "    Nref, Nsys = T.sum(), O.sum()\n",
        "\n",
        "    prec = float(TP) / float(Nsys + eps)\n",
        "    recall = float(TP) / float(Nref + eps)\n",
        "    f1_score = 2 * prec * recall / (prec + recall + eps)\n",
        "    return f1_score\n",
        "\n",
        "\n",
        "def er_overall_framewise(O, T):\n",
        "    if len(O.shape) == 3:\n",
        "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "\n",
        "    FP = np.logical_and(T == 0, O == 1).sum(1)\n",
        "    FN = np.logical_and(T == 1, O == 0).sum(1)\n",
        "\n",
        "    S = np.minimum(FP, FN).sum()\n",
        "    D = np.maximum(0, FN-FP).sum()\n",
        "    I = np.maximum(0, FP-FN).sum()\n",
        "\n",
        "    Nref = T.sum()\n",
        "    ER = (S+D+I) / (Nref + 0.0)\n",
        "    return ER\n",
        "\n",
        "\n",
        "def f1_framewise(O, T):\n",
        "    if len(O.shape) == 3:\n",
        "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "    TP = ((2 * T - O) == 1).sum(axis=1)\n",
        "    Nref, Nsys = T.sum(axis=1), O.sum(axis=1)\n",
        "\n",
        "    prec = (TP + eps) / (Nsys + eps)\n",
        "    recall = (TP + eps) / (Nref + eps)\n",
        "    f1_score = 2 * prec * recall / (prec + recall + eps)\n",
        "    return f1_score\n",
        "\n",
        "\n",
        "def f1_1sec(O, T, block_size):\n",
        "    if len(O.shape) == 3:\n",
        "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "    new_size = int(O.shape[0] / block_size)\n",
        "    O_block = np.zeros((new_size, O.shape[1]))\n",
        "    T_block = np.zeros((new_size, O.shape[1]))\n",
        "    for i in range(0, new_size):\n",
        "        O_block[i,] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
        "        T_block[i,] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
        "    return f1_framewise(O_block, T_block)\n",
        "\n",
        "\n",
        "def f1_overall_1sec(O, T, block_size):\n",
        "    if len(O.shape) == 3:\n",
        "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "    new_size = int(np.ceil(O.shape[0] / block_size))\n",
        "    O_block = np.zeros((new_size, O.shape[1]))\n",
        "    T_block = np.zeros((new_size, O.shape[1]))\n",
        "    for i in range(0, new_size):\n",
        "        O_block[i,] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
        "        T_block[i,] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
        "    return f1_overall_framewise(O_block, T_block)\n",
        "\n",
        "\n",
        "def er_overall_1sec(O, T, block_size):\n",
        "    if len(O.shape) == 3:\n",
        "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "    new_size = int(O.shape[0] / (block_size))\n",
        "    O_block = np.zeros((new_size, O.shape[1]))\n",
        "    T_block = np.zeros((new_size, O.shape[1]))\n",
        "    for i in range(0, new_size):\n",
        "        O_block[i,] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
        "        T_block[i,] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
        "    return er_overall_framewise(O_block, T_block)\n",
        "\n",
        "\n",
        "def compute_sed_scores(pred, y, nb_frames_1s):\n",
        "    \"\"\"Compute TUT metrics\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pred : matrix\n",
        "        predicted matrix / system output\n",
        "\n",
        "    y : matrix\n",
        "        reference matrix\n",
        "\n",
        "    hop_length_seconds : float\n",
        "        used frame hop length\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scores : dict\n",
        "    \"\"\"\n",
        "    f1o = f1_overall_1sec(pred, y, nb_frames_1s)\n",
        "    ero = er_overall_1sec(pred, y, nb_frames_1s)\n",
        "    scores = [ero, f1o]\n",
        "    return scores\n",
        "\n",
        "def distance_between_spherical_coordinates_rad(az1, ele1, az2, ele2):\n",
        "    \"\"\"\n",
        "    Angular distance between two spherical coordinates\n",
        "    MORE: https://en.wikipedia.org/wiki/Great-circle_distance\n",
        "    :return: angular distance in degrees\n",
        "    \"\"\"\n",
        "    dist = np.sin(ele1) * np.sin(ele2) + np.cos(ele1) * np.cos(ele2) * np.cos(np.abs(az1 - az2))\n",
        "    # Making sure the dist values are in -1 to 1 range, else np.arccos kills the job\n",
        "    dist = np.clip(dist, -1, 1)\n",
        "    dist = np.arccos(dist) * 180 / np.pi\n",
        "    return dist\n",
        "\n",
        "def distance_between_cartesian_coordinates(x1, y1, z1, x2, y2, z2):\n",
        "    \"\"\"\n",
        "    Angular distance between two cartesian coordinates\n",
        "    MORE: https://en.wikipedia.org/wiki/Great-circle_distance\n",
        "    Check 'From chord length' section\n",
        "    :return: angular distance in degrees\n",
        "    \"\"\"\n",
        "    dist = np.sqrt((x1-x2) ** 2 + (y1-y2) ** 2 + (z1-z2) ** 2)\n",
        "    dist = 2 * np.arcsin(dist / 2.0) * 180/np.pi\n",
        "    return dist\n",
        "\n",
        "\n",
        "def cart2sph(x,y,z):\n",
        "    azimuth = np.arctan2(y,x)\n",
        "    elevation = np.arctan2(z,np.sqrt(x**2 + y**2))\n",
        "    r = np.sqrt(x**2 + y**2 + z**2)\n",
        "    return azimuth, elevation, r\n",
        "\n",
        "\n",
        "def sph2cart(azimuth,elevation,r):\n",
        "    x = r * np.cos(elevation) * np.cos(azimuth)\n",
        "    y = r * np.cos(elevation) * np.sin(azimuth)\n",
        "    z = r * np.sin(elevation)\n",
        "    return x, y, z\n",
        "\n",
        "\n",
        "def compute_doa_scores_regr_xy(pred, gt, pred_sed, gt_sed):\n",
        "    nb_src_gt_list = np.zeros(gt.shape[0]).astype(int)\n",
        "    nb_src_pred_list = np.zeros(gt.shape[0]).astype(int)\n",
        "    good_frame_cnt = 0\n",
        "    less_frame_cnt = 0\n",
        "    more_frame_cnt = 0\n",
        "    doa_loss_gt = 0.0\n",
        "    doa_loss_gt_cnt = 0\n",
        "    doa_loss_pred = 0.0\n",
        "    doa_loss_pred_cnt = 0\n",
        "    nb_sed = gt_sed.shape[-1]\n",
        "    for frame_cnt, sed_frame in enumerate(gt_sed):\n",
        "        nb_src_gt_list[frame_cnt] = int(np.sum(sed_frame))\n",
        "        nb_src_pred_list[frame_cnt] = int(np.sum(pred_sed[frame_cnt]))\n",
        "        if nb_src_gt_list[frame_cnt] > nb_src_pred_list[frame_cnt]:\n",
        "            less_frame_cnt = less_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] < nb_src_pred_list[frame_cnt]:\n",
        "            more_frame_cnt = more_frame_cnt + 1\n",
        "        else:\n",
        "            good_frame_cnt = good_frame_cnt + 1\n",
        "\n",
        "        # DOA Loss with respect to groundtruth\n",
        "        doa_frame_gt_x = gt[frame_cnt][:nb_sed][sed_frame == 1]\n",
        "        doa_frame_gt_y = gt[frame_cnt][nb_sed:2*nb_sed][sed_frame == 1]\n",
        "\n",
        "        doa_frame_pred_x = pred[frame_cnt][:nb_sed][sed_frame == 1]\n",
        "        doa_frame_pred_y = pred[frame_cnt][nb_sed:2*nb_sed][sed_frame == 1]\n",
        "\n",
        "        for cnt in range(nb_src_gt_list[frame_cnt]):\n",
        "            doa_loss_gt += np.sqrt(\n",
        "                (doa_frame_gt_x[cnt] - doa_frame_pred_x[cnt]) ** 2 +\n",
        "                (doa_frame_gt_y[cnt] - doa_frame_pred_y[cnt]) ** 2\n",
        "            )\n",
        "\n",
        "\n",
        "            doa_loss_gt_cnt += 1\n",
        "\n",
        "        # DOA Loss with respect to predicted confidence\n",
        "        sed_frame_pred = pred_sed[frame_cnt]\n",
        "        doa_frame_gt_x = gt[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "        doa_frame_gt_y = gt[frame_cnt][nb_sed:2*nb_sed][sed_frame_pred == 1]\n",
        "\n",
        "        doa_frame_pred_x = pred[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "        doa_frame_pred_y = pred[frame_cnt][nb_sed:2*nb_sed][sed_frame_pred == 1]\n",
        "\n",
        "        for cnt in range(nb_src_pred_list[frame_cnt]):\n",
        "            doa_loss_pred += np.sqrt(\n",
        "                (doa_frame_gt_x[cnt] - doa_frame_pred_x[cnt]) ** 2 +\n",
        "                (doa_frame_gt_y[cnt] - doa_frame_pred_y[cnt]) ** 2\n",
        "            )\n",
        "            doa_loss_pred_cnt += 1\n",
        "\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    if doa_loss_gt_cnt:\n",
        "        doa_loss_gt /= doa_loss_gt_cnt\n",
        "\n",
        "    max_nb_src_gt = np.max(nb_src_gt_list)\n",
        "    conf_mat = confusion_matrix(nb_src_gt_list, nb_src_pred_list)\n",
        "    conf_mat = conf_mat / (eps + np.sum(conf_mat, 1)[:, None].astype('float'))\n",
        "    avg_accuracy = np.mean(np.diag(conf_mat[:max_nb_src_gt, :max_nb_src_gt]))  # In frames where more DOA's are\n",
        "    # predicted, the conf_mat is no more square matrix, and the average skew's the results. Hence we always calculate\n",
        "    # the accuracy wrt gt number of sources\n",
        "    er_metric = [avg_accuracy, doa_loss_gt, doa_loss_pred, doa_loss_gt_cnt, doa_loss_pred_cnt, good_frame_cnt]\n",
        "    return er_metric, conf_mat\n",
        "\n",
        "\n",
        "def compute_doa_scores_regr_xyz(pred, gt, pred_sed, gt_sed):\n",
        "    nb_src_gt_list = np.zeros(gt.shape[0]).astype(int)\n",
        "    nb_src_pred_list = np.zeros(gt.shape[0]).astype(int)\n",
        "    good_frame_cnt = 0\n",
        "    less_frame_cnt = 0\n",
        "    more_frame_cnt = 0\n",
        "    doa_loss_gt = 0.0\n",
        "    doa_loss_gt_cnt = 0\n",
        "    doa_loss_pred = 0.0\n",
        "    doa_loss_pred_cnt = 0\n",
        "    nb_sed = gt_sed.shape[-1]\n",
        "\n",
        "    for frame_cnt, sed_frame in enumerate(gt_sed):\n",
        "        nb_src_gt_list[frame_cnt] = int(np.sum(sed_frame))\n",
        "        nb_src_pred_list[frame_cnt] = int(np.sum(pred_sed[frame_cnt]))\n",
        "        if nb_src_gt_list[frame_cnt] > nb_src_pred_list[frame_cnt]:\n",
        "            less_frame_cnt = less_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] < nb_src_pred_list[frame_cnt]:\n",
        "            more_frame_cnt = more_frame_cnt + 1\n",
        "        else:\n",
        "            good_frame_cnt = good_frame_cnt + 1\n",
        "\n",
        "        # DOA Loss with respect to groundtruth\n",
        "        doa_frame_gt_x = gt[frame_cnt][:nb_sed][sed_frame == 1]\n",
        "        doa_frame_gt_y = gt[frame_cnt][nb_sed:2*nb_sed][sed_frame == 1]\n",
        "        doa_frame_gt_z = gt[frame_cnt][2*nb_sed:][sed_frame == 1]\n",
        "\n",
        "        doa_frame_pred_x = pred[frame_cnt][:nb_sed][sed_frame == 1]\n",
        "        doa_frame_pred_y = pred[frame_cnt][nb_sed:2*nb_sed][sed_frame == 1]\n",
        "        doa_frame_pred_z = pred[frame_cnt][2*nb_sed:][sed_frame == 1]\n",
        "\n",
        "        for cnt in range(nb_src_gt_list[frame_cnt]):\n",
        "            doa_loss_gt += np.sqrt(\n",
        "                (doa_frame_gt_x[cnt] - doa_frame_pred_x[cnt]) ** 2 +\n",
        "                (doa_frame_gt_y[cnt] - doa_frame_pred_y[cnt]) ** 2 +\n",
        "                (doa_frame_gt_z[cnt] - doa_frame_pred_z[cnt]) ** 2\n",
        "            )\n",
        "            doa_loss_gt_cnt += 1\n",
        "\n",
        "        # DOA Loss with respect to predicted confidence\n",
        "        sed_frame_pred = pred_sed[frame_cnt]\n",
        "        doa_frame_gt_x = gt[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "        doa_frame_gt_y = gt[frame_cnt][nb_sed:2*nb_sed][sed_frame_pred == 1]\n",
        "        doa_frame_gt_z = gt[frame_cnt][2*nb_sed:][sed_frame_pred == 1]\n",
        "\n",
        "        doa_frame_pred_x = pred[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "        doa_frame_pred_y = pred[frame_cnt][nb_sed:2*nb_sed][sed_frame_pred == 1]\n",
        "        doa_frame_pred_z = pred[frame_cnt][2*nb_sed:][sed_frame_pred == 1]\n",
        "\n",
        "        for cnt in range(nb_src_pred_list[frame_cnt]):\n",
        "            doa_loss_pred += np.sqrt(\n",
        "                (doa_frame_gt_x[cnt] - doa_frame_pred_x[cnt]) ** 2 +\n",
        "                (doa_frame_gt_y[cnt] - doa_frame_pred_y[cnt]) ** 2 +\n",
        "                (doa_frame_gt_z[cnt] - doa_frame_pred_z[cnt]) ** 2\n",
        "            )\n",
        "            doa_loss_pred_cnt += 1\n",
        "\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    if doa_loss_gt_cnt:\n",
        "        doa_loss_gt /= doa_loss_gt_cnt\n",
        "\n",
        "    max_nb_src_gt = np.max(nb_src_gt_list)\n",
        "    conf_mat = confusion_matrix(nb_src_gt_list, nb_src_pred_list)\n",
        "    conf_mat = conf_mat / (eps + np.sum(conf_mat, 1)[:, None].astype('float'))\n",
        "    avg_accuracy = np.mean(np.diag(conf_mat[:max_nb_src_gt, :max_nb_src_gt]))  # In frames where more DOA's are\n",
        "    # predicted, the conf_mat is no more square matrix, and the average skew's the results. Hence we always calculate\n",
        "    # the accuracy wrt gt number of sources\n",
        "    er_metric = [avg_accuracy, doa_loss_gt, doa_loss_pred, doa_loss_gt_cnt, doa_loss_pred_cnt, good_frame_cnt]\n",
        "    return er_metric, conf_mat\n",
        "\n",
        "###############################################################\n",
        "# Functions for format conversions\n",
        "###############################################################\n",
        "\n",
        "def description_file_to_output_format(_desc_file_dict, _unique_classes, _hop_length_sec):\n",
        "    \"\"\"\n",
        "    Reads description file in csv format. Outputs, the dcase format results in dictionary, and additionally writes it\n",
        "    to the _output_file\n",
        "    :param _unique_classes: unique classes dictionary, maps class name to class index\n",
        "    :param _desc_file_dict: full path of the description file\n",
        "    :param _hop_length_sec: hop length in seconds\n",
        "    :return: _output_dict: dcase output in dicitionary format\n",
        "    \"\"\"\n",
        "\n",
        "    _output_dict = {}\n",
        "    for _ind, _tmp_start_sec in enumerate(_desc_file_dict['start']):\n",
        "        _tmp_class = _unique_classes[_desc_file_dict['class'][_ind]]\n",
        "        _tmp_azi = _desc_file_dict['azi'][_ind]\n",
        "        _tmp_ele = _desc_file_dict['ele'][_ind]\n",
        "        _tmp_end_sec = _desc_file_dict['end'][_ind]\n",
        "\n",
        "        #Conversion from gt azimuthal coodrdinates in xyz in 180 scale\n",
        "        _tmp_x = np.cos(_tmp_azi * np.pi / 180) * 180\n",
        "        _tmp_y = np.sin(_tmp_azi * np.pi / 180) * 180\n",
        "        _tmp_z = np.sin(_tmp_ele * np.pi / 180) * 180\n",
        "\n",
        "        _start_frame = int(_tmp_start_sec / _hop_length_sec)\n",
        "        _end_frame = int(_tmp_end_sec / _hop_length_sec)\n",
        "        for _frame_ind in range(_start_frame, _end_frame + 1):\n",
        "            if _frame_ind not in _output_dict:\n",
        "                _output_dict[_frame_ind] = []\n",
        "            _output_dict[_frame_ind].append([_tmp_class, _tmp_x, _tmp_y, _tmp_z])\n",
        "\n",
        "    return _output_dict\n",
        "\n",
        "def load_output_format_file(_output_format_file):\n",
        "    \"\"\"\n",
        "    Loads DCASE output format csv file and returns it in dictionary format\n",
        "    :param _output_format_file: DCASE output format CSV\n",
        "    :return: _output_dict: dictionary\n",
        "    \"\"\"\n",
        "    _output_dict = {}\n",
        "    _fid = open(_output_format_file, 'r')\n",
        "    # next(_fid)\n",
        "    for _line in _fid:\n",
        "        _words = _line.strip().split(',')\n",
        "        _frame_ind = int(_words[0])\n",
        "        if _frame_ind not in _output_dict:\n",
        "            _output_dict[_frame_ind] = []\n",
        "        _sed_class = int(_words[1])\n",
        "        _doa_x = int(_words[2])\n",
        "        _doa_y = int(_words[3])\n",
        "        _doa_z = int(_words[4])\n",
        "        _output_dict[_frame_ind].append([_sed_class, _doa_x, _doa_y, _doa_z])\n",
        "    _fid.close()\n",
        "    return _output_dict\n",
        "\n",
        "def compute_doa_scores_regr(pred_doa_rad, gt_doa_rad, pred_sed, gt_sed):\n",
        "    \"\"\"\n",
        "        Compute DOA metrics when DOA is estimated using regression approach\n",
        "    :param pred_doa_rad: predicted doa_labels is of dimension [nb_frames, 2*nb_classes],\n",
        "                        nb_classes each for azimuth and elevation angles,\n",
        "                        if active, the DOA values will be in RADIANS, else, it will contain default doa values\n",
        "    :param gt_doa_rad: reference doa_labels is of dimension [nb_frames, 2*nb_classes],\n",
        "                    nb_classes each for azimuth and elevation angles,\n",
        "                    if active, the DOA values will be in RADIANS, else, it will contain default doa values\n",
        "    :param pred_sed: predicted sed label of dimension [nb_frames, nb_classes] which is 1 for active sound event else zero\n",
        "    :param gt_sed: reference sed label of dimension [nb_frames, nb_classes] which is 1 for active sound event else zero\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    nb_src_gt_list = np.zeros(gt_doa_rad.shape[0]).astype(int)\n",
        "    nb_src_pred_list = np.zeros(gt_doa_rad.shape[0]).astype(int)\n",
        "    good_frame_cnt = 0\n",
        "    doa_loss_pred = 0.0\n",
        "    nb_sed = gt_sed.shape[-1]\n",
        "\n",
        "    less_est_cnt, less_est_frame_cnt = 0, 0\n",
        "    more_est_cnt, more_est_frame_cnt = 0, 0\n",
        "\n",
        "    for frame_cnt, sed_frame in enumerate(gt_sed):\n",
        "        nb_src_gt_list[frame_cnt] = int(np.sum(sed_frame))\n",
        "        nb_src_pred_list[frame_cnt] = int(np.sum(pred_sed[frame_cnt]))\n",
        "\n",
        "        # good_frame_cnt includes frames where the nb active sources were zero in both groundtruth and prediction\n",
        "        if nb_src_gt_list[frame_cnt] == nb_src_pred_list[frame_cnt]:\n",
        "            good_frame_cnt = good_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] > nb_src_pred_list[frame_cnt]:\n",
        "            less_est_cnt = less_est_cnt + nb_src_gt_list[frame_cnt] - nb_src_pred_list[frame_cnt]\n",
        "            less_est_frame_cnt = less_est_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] < nb_src_pred_list[frame_cnt]:\n",
        "            more_est_cnt = more_est_cnt + nb_src_pred_list[frame_cnt] - nb_src_gt_list[frame_cnt]\n",
        "            more_est_frame_cnt = more_est_frame_cnt + 1\n",
        "\n",
        "        # when nb_ref_doa > nb_estimated_doa, ignores the extra ref doas and scores only the nearest matching doas\n",
        "        # similarly, when nb_estimated_doa > nb_ref_doa, ignores the extra estimated doa and scores the remaining matching doas\n",
        "        if nb_src_gt_list[frame_cnt] and nb_src_pred_list[frame_cnt]:\n",
        "            # DOA Loss with respect to predicted confidence\n",
        "            sed_frame_gt = gt_sed[frame_cnt]\n",
        "            doa_frame_gt_azi = gt_doa_rad[frame_cnt][:nb_sed][sed_frame_gt == 1]\n",
        "            doa_frame_gt_ele = gt_doa_rad[frame_cnt][nb_sed:][sed_frame_gt == 1]\n",
        "\n",
        "            sed_frame_pred = pred_sed[frame_cnt]\n",
        "            doa_frame_pred_azi = pred_doa_rad[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "            doa_frame_pred_ele = pred_doa_rad[frame_cnt][nb_sed:][sed_frame_pred == 1]\n",
        "\n",
        "            doa_loss_pred += distance_between_gt_pred(np.vstack((doa_frame_gt_azi, doa_frame_gt_ele)).T,\n",
        "                                                      np.vstack((doa_frame_pred_azi, doa_frame_pred_ele)).T)\n",
        "\n",
        "    doa_loss_pred_cnt = np.sum(nb_src_pred_list)\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    frame_recall = good_frame_cnt / float(gt_sed.shape[0])\n",
        "    er_metric = [doa_loss_pred, frame_recall, doa_loss_pred_cnt, good_frame_cnt, more_est_cnt, less_est_cnt]\n",
        "    return er_metric\n",
        "\n",
        "\n",
        "\n",
        "def distance_between_gt_pred(gt_list_rad, pred_list_rad):\n",
        "    \"\"\"\n",
        "    Shortest distance between two sets of spherical coordinates. Given a set of groundtruth spherical coordinates,\n",
        "     and its respective predicted coordinates, we calculate the spherical distance between each of the spherical\n",
        "     coordinate pairs resulting in a matrix of distances, where one axis represents the number of groundtruth\n",
        "     coordinates and the other the predicted coordinates. The number of estimated peaks need not be the same as in\n",
        "     groundtruth, thus the distance matrix is not always a square matrix. We use the hungarian algorithm to find the\n",
        "     least cost in this distance matrix.\n",
        "    :param gt_list_rad: list of ground-truth spherical coordinates\n",
        "    :param pred_list_rad: list of predicted spherical coordinates\n",
        "    :return: cost -  distance\n",
        "    :return: less - number of DOA's missed\n",
        "    :return: extra - number of DOA's over-estimated\n",
        "    \"\"\"\n",
        "\n",
        "    gt_len, pred_len = gt_list_rad.shape[0], pred_list_rad.shape[0]\n",
        "    ind_pairs = np.array([[x, y] for y in range(pred_len) for x in range(gt_len)])\n",
        "    cost_mat = np.zeros((gt_len, pred_len))\n",
        "\n",
        "    if gt_len and pred_len:\n",
        "        az1, ele1, az2, ele2 = gt_list_rad[ind_pairs[:, 0], 0], gt_list_rad[ind_pairs[:, 0], 1], \\\n",
        "                               pred_list_rad[ind_pairs[:, 1], 0], pred_list_rad[ind_pairs[:, 1], 1]\n",
        "        cost_mat[ind_pairs[:, 0], ind_pairs[:, 1]] = distance_between_spherical_coordinates_rad(az1, ele1, az2, ele2)\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_mat)\n",
        "    cost = cost_mat[row_ind, col_ind].sum()\n",
        "    return cost\n",
        "\n",
        "\n",
        "def regression_label_format_to_output_format(_feat_cls, _sed_labels, _doa_labels_deg):\n",
        "    \"\"\"\n",
        "    Converts the sed (classification) and doa labels predicted in regression format to dcase output format.\n",
        "    :param _feat_cls: feature or data generator class instance\n",
        "    :param _sed_labels: SED labels matrix [nb_frames, nb_classes]\n",
        "    :param _doa_labels_deg: DOA labels matrix [nb_frames, 2*nb_classes] in degrees\n",
        "    :return: _output_dict: returns a dict containing dcase output format\n",
        "    \"\"\"\n",
        "\n",
        "    _unique_classes = _feat_cls.get_classes()\n",
        "    _nb_classes = len(_unique_classes)\n",
        "    doa_frame_pred_x = _doa_labels_deg[:, :_nb_classes]\n",
        "    doa_frame_pred_y = _doa_labels_deg[:, _nb_classes:2*_nb_classes]\n",
        "    doa_frame_pred_z = _doa_labels_deg[:, 2*_nb_classes:]\n",
        "\n",
        "\n",
        "    _output_dict = {}\n",
        "    for _frame_ind in range(_sed_labels.shape[0]):\n",
        "        _tmp_ind = np.where(_sed_labels[_frame_ind, :])\n",
        "        if len(_tmp_ind[0]):\n",
        "            _output_dict[_frame_ind] = []\n",
        "            for _tmp_class in _tmp_ind[0]:\n",
        "                _output_dict[_frame_ind].append([_tmp_class, doa_frame_pred_x[_frame_ind, _tmp_class],\n",
        "                                                 doa_frame_pred_y[_frame_ind, _tmp_class], doa_frame_pred_z[_frame_ind, _tmp_class]])\n",
        "    return _output_dict\n",
        "\n",
        "\n",
        "def classification_label_format_to_output_format(_feat_cls, _labels):\n",
        "    \"\"\"\n",
        "    Converts the seld labels predicted in classification format to dcase output format.\n",
        "    :param _feat_cls: feature or data generator class instance\n",
        "    :param _labels: SED labels matrix [nb_frames, nb_classes, nb_azi*nb_ele]\n",
        "    :return: _output_dict: returns a dict containing dcase output format\n",
        "    \"\"\"\n",
        "    _output_dict = {}\n",
        "    for _frame_ind in range(_labels.shape[0]):\n",
        "        _tmp_class_ind = np.where(_labels[_frame_ind].sum(1))\n",
        "        if len(_tmp_class_ind[0]):\n",
        "            _output_dict[_frame_ind] = []\n",
        "            for _tmp_class in _tmp_class_ind[0]:\n",
        "                _tmp_spatial_ind = np.where(_labels[_frame_ind, _tmp_class])\n",
        "                for _tmp_spatial in _tmp_spatial_ind[0]:\n",
        "                    _azi, _ele = _feat_cls.get_matrix_index(_tmp_spatial)\n",
        "                    _output_dict[_frame_ind].append(\n",
        "                        [_tmp_class, _azi, _ele])\n",
        "\n",
        "    return _output_dict\n",
        "\n",
        "\n",
        "def write_output_format_file(_output_format_file, _output_format_dict):\n",
        "    \"\"\"\n",
        "    Writes DCASE output format csv file, given output format dictionary\n",
        "    :param _output_format_file:\n",
        "    :param _output_format_dict:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    _fid = open(_output_format_file, 'w')\n",
        "    for _frame_ind in _output_format_dict.keys():\n",
        "        for _value in _output_format_dict[_frame_ind]:\n",
        "            _fid.write('{},{},{},{},{}\\n'.format(int(_frame_ind), int(_value[0]), int(_value[1]), int(_value[2]), int(_value[3])))\n",
        "    _fid.close()\n",
        "\n",
        "\n",
        "def output_format_dict_to_classification_labels(_output_dict, _feat_cls):\n",
        "\n",
        "    _unique_classes = _feat_cls.get_classes()\n",
        "    _nb_classes = len(_unique_classes)\n",
        "    _azi_list, _ele_list = _feat_cls.get_azi_ele_list()\n",
        "    _max_frames = _feat_cls.get_nb_frames()\n",
        "    _labels = np.zeros((_max_frames, _nb_classes, len(_azi_list) * len(_ele_list)))\n",
        "\n",
        "    for _frame_cnt in _output_dict.keys():\n",
        "        if _frame_cnt < _max_frames:\n",
        "            for _tmp_doa in _output_dict[_frame_cnt]:\n",
        "                # Making sure the doa's are within the limits\n",
        "                _tmp_doa[1] = np.clip(_tmp_doa[1], _azi_list[0], _azi_list[-1])\n",
        "                _tmp_doa[2] = np.clip(_tmp_doa[2], _ele_list[0], _ele_list[-1])\n",
        "\n",
        "                # create label\n",
        "                _labels[_frame_cnt, _tmp_doa[0], int(_feat_cls.get_list_index(_tmp_doa[1], _tmp_doa[2]))] = 1\n",
        "\n",
        "    return _labels\n",
        "\n",
        "\n",
        "def compute_seld_metrics_from_output_format_dict(_pred_dict, _gt_dict, _feat_cls):\n",
        "    \"\"\"\n",
        "        Compute SELD metrics between _gt_dict and_pred_dict in DCASE output format\n",
        "    :param _pred_dict: dcase output format dict\n",
        "    :param _gt_dict: dcase output format dict\n",
        "    :param _feat_cls: feature or data generator class\n",
        "    :return: the seld metrics\n",
        "    \"\"\"\n",
        "    _gt_labels = output_format_dict_to_classification_labels(_gt_dict, _feat_cls)\n",
        "    _pred_labels = output_format_dict_to_classification_labels(_pred_dict, _feat_cls)\n",
        "\n",
        "    _er, _f = compute_sed_scores(_pred_labels.max(2), _gt_labels.max(2), _feat_cls.nb_frames_1s())\n",
        "    _doa_err, _frame_recall, d1, d2, d3, d4 = compute_doa_scores_clas(_pred_labels, _gt_labels, _feat_cls)\n",
        "    _seld_scr = compute_seld_metric([_er, _f], [_doa_err, _frame_recall])\n",
        "    return _seld_scr, _er, _f, _doa_err, _frame_recall\n",
        "\n",
        "\n",
        "def compute_doa_scores_clas(pred_doa_thresholded, gt_doa, data_gen_test):\n",
        "    '''\n",
        "    Compute DOA metrics when DOA is estimated using classification approach\n",
        "    :param pred_doa_thresholded: predicted results of dimension [nb_frames, nb_classes, nb_azi*nb_ele],\n",
        "                                with value 1 when sound event active, else 0\n",
        "    :param gt_doa: reference results of dimension [nb_frames, nb_classes, nb_azi*nb_ele],\n",
        "                    with value 1 when sound event active, else 0\n",
        "    :param data_gen_test: feature or data generator class\n",
        "    :return: DOA metrics\n",
        "    '''\n",
        "    doa_loss_pred_cnt = np.sum(pred_doa_thresholded)\n",
        "\n",
        "    doa_loss_pred = 0\n",
        "    nb_good_pks = 0\n",
        "\n",
        "    less_est_cnt, less_est_frame_cnt = 0, 0\n",
        "    more_est_cnt, more_est_frame_cnt = 0, 0\n",
        "\n",
        "    for frame in range(pred_doa_thresholded.shape[0]):\n",
        "        nb_gt_peaks = int(np.sum(gt_doa[frame, :]))\n",
        "        nb_pred_peaks = int(np.sum(pred_doa_thresholded[frame, :]))\n",
        "\n",
        "        # good_frame_cnt includes frames where the nb active sources were zero in both groundtruth and prediction\n",
        "        if nb_gt_peaks == nb_pred_peaks:\n",
        "            nb_good_pks += 1\n",
        "        elif nb_gt_peaks > nb_pred_peaks:\n",
        "            less_est_frame_cnt += 1\n",
        "            less_est_cnt += (nb_gt_peaks - nb_pred_peaks)\n",
        "        elif nb_pred_peaks > nb_gt_peaks:\n",
        "            more_est_frame_cnt += 1\n",
        "            more_est_cnt += (nb_pred_peaks - nb_gt_peaks)\n",
        "\n",
        "        # when nb_ref_doa > nb_estimated_doa, ignores the extra ref doas and scores only the nearest matching doas\n",
        "        # similarly, when nb_estimated_doa > nb_ref_doa, ignores the extra estimated doa and scores the remaining matching doas\n",
        "        if nb_gt_peaks and nb_pred_peaks:\n",
        "            pred_ind = np.where(pred_doa_thresholded[frame] == 1)[1]\n",
        "            pred_list_rad = np.array(data_gen_test.get_matrix_index(pred_ind)) * np.pi / 180\n",
        "\n",
        "            gt_ind = np.where(gt_doa[frame] == 1)[1]\n",
        "            gt_list_rad = np.array(data_gen_test.get_matrix_index(gt_ind)) * np.pi / 180\n",
        "\n",
        "            frame_dist = distance_between_gt_pred(gt_list_rad.T, pred_list_rad.T)\n",
        "            doa_loss_pred += frame_dist\n",
        "\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    frame_recall = nb_good_pks / float(pred_doa_thresholded.shape[0])\n",
        "    er_metric = [doa_loss_pred, frame_recall, doa_loss_pred_cnt, nb_good_pks, more_est_cnt, less_est_cnt]\n",
        "    return er_metric\n",
        "\n",
        "def compute_seld_metric(sed_error, doa_error):\n",
        "    \"\"\"\n",
        "    Compute SELD metric from sed and doa errors.\n",
        "    :param sed_error: [error rate (0 to 1 range), f score (0 to 1 range)]\n",
        "    :param doa_error: [doa error (in degrees), frame recall (0 to 1 range)]\n",
        "    :return: seld metric result\n",
        "    \"\"\"\n",
        "    seld_metric = np.mean([\n",
        "        sed_error[0],\n",
        "        1 - sed_error[1],\n",
        "        doa_error[0]/180,\n",
        "        1 - doa_error[1]]\n",
        "        )\n",
        "    return seld_metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TlgXGWWF1Xa",
        "colab_type": "text"
      },
      "source": [
        "#***Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0yrc7zeF48R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# The SELDnet architecture\n",
        "#\n",
        "\n",
        "keras.backend.set_image_data_format('channels_first')\n",
        "\n",
        "def get_model(data_in, data_out, dropout_rate, nb_cnn2d_filt, pool_size,\n",
        "                                rnn_size, fnn_size, classification_mode, weights):\n",
        "    # model definition\n",
        "    spec_start = Input(shape=(data_in[-3], data_in[-2], data_in[-1]))\n",
        "    spec_cnn = spec_start\n",
        "    for i, convCnt in enumerate(pool_size):\n",
        "        spec_cnn = Conv2D(filters=nb_cnn2d_filt, kernel_size=(3, 3), padding='same')(spec_cnn)\n",
        "        spec_cnn = BatchNormalization()(spec_cnn)\n",
        "        spec_cnn = Activation('relu')(spec_cnn)\n",
        "        spec_cnn = MaxPooling2D(pool_size=(1, pool_size[i]))(spec_cnn)\n",
        "        spec_cnn = Dropout(dropout_rate)(spec_cnn)\n",
        "    spec_cnn = Permute((2, 1, 3))(spec_cnn)\n",
        "\n",
        "    spec_rnn = Reshape((data_in[-2], -1))(spec_cnn)\n",
        "    for nb_rnn_filt in rnn_size:\n",
        "        spec_rnn = Bidirectional(\n",
        "            GRU(nb_rnn_filt, activation='tanh', dropout=dropout_rate, recurrent_dropout=dropout_rate,\n",
        "                return_sequences=True),\n",
        "            merge_mode='mul'\n",
        "        )(spec_rnn)\n",
        "\n",
        "    doa = spec_rnn\n",
        "    for nb_fnn_filt in fnn_size:\n",
        "        doa = TimeDistributed(Dense(nb_fnn_filt))(doa)\n",
        "        doa = Dropout(dropout_rate)(doa)\n",
        "\n",
        "    doa = TimeDistributed(Dense(data_out[1][-1]))(doa)\n",
        "    doa = Activation('tanh', name='doa_out')(doa)\n",
        "\n",
        "    # SED\n",
        "    sed = spec_rnn\n",
        "    for nb_fnn_filt in fnn_size:\n",
        "        sed = TimeDistributed(Dense(nb_fnn_filt))(sed)\n",
        "        sed = Dropout(dropout_rate)(sed)\n",
        "    sed = TimeDistributed(Dense(data_out[0][-1]))(sed)\n",
        "    sed = Activation('sigmoid', name='sed_out')(sed)\n",
        "\n",
        "    model = Model(inputs=spec_start, outputs=[sed, doa])\n",
        "    model.compile(optimizer=Adam(), loss=['binary_crossentropy', 'mse'], loss_weights=weights, metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md2QwkPE0m-q",
        "colab_type": "text"
      },
      "source": [
        "#***Training***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps2WK6Ar0idU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot.switch_backend('agg')\n",
        "\n",
        "def return_sed_doa_scores(model, gt, data_gen_test):\n",
        "    data_in, data_out = data_gen_test.get_data_sizes()\n",
        "\n",
        "    sed_gt = reshape_3Dto2D(gt[0])\n",
        "    doa_gt = reshape_3Dto2D(gt[1])\n",
        "\n",
        "    pred = model.predict_generator(\n",
        "                generator=data_gen_test.generate(),\n",
        "                steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "    sed_pred = reshape_3Dto2D(pred[0]) > 0.5\n",
        "    doa_pred = reshape_3Dto2D(pred[1])\n",
        "\n",
        "    sed_scores = compute_sed_scores(sed_pred, sed_gt, data_gen_test.nb_frames_1s())\n",
        "    if params['azi_only']:\n",
        "        doa_scores, conf_mat = compute_doa_scores_regr_xy(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "    else:\n",
        "        doa_scores, conf_mat = compute_doa_scores_regr_xyz(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "        \n",
        "    print('SED Metrics: ER_overall: {}, F1_overall: {}'.format(sed_scores[0], sed_scores[1]))\n",
        "    print('DOA Metrics: doa_loss_gt: {}, doa_loss_pred: {}, good_pks_ratio: {}'.format(\n",
        "        doa_scores[1], doa_scores[2], doa_scores[5] / float(sed_gt.shape[0])))\n",
        "    \n",
        "    return sed_scores, doa_scores\n",
        "    \n",
        "\n",
        "def collect_test_labels(_data_gen_test, _data_out, classification_mode, quick_test):\n",
        "    # Collecting ground truth for test data\n",
        "    nb_batch = 2 if quick_test else _data_gen_test.get_total_batches_in_data()\n",
        "\n",
        "    batch_size = _data_out[0][0]\n",
        "    gt_sed = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[0][2]))\n",
        "    gt_doa = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[1][2]))\n",
        "\n",
        "    print(\"nb_batch in test: {}\".format(nb_batch))\n",
        "    cnt = 0\n",
        "    for tmp_feat, tmp_label in _data_gen_test.generate():\n",
        "        gt_sed[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[0]\n",
        "        gt_doa[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[1]\n",
        "        cnt = cnt + 1\n",
        "        if cnt == nb_batch:\n",
        "            break\n",
        "    return gt_sed.astype(int), gt_doa\n",
        "\n",
        "\n",
        "def plot_functions(fig_name, _tr_loss, _val_loss, _sed_loss, _doa_loss, _epoch_metric_loss):\n",
        "    plot.figure()\n",
        "    nb_epoch = len(_tr_loss)\n",
        "    plot.subplot(311)\n",
        "    plot.plot(range(nb_epoch), _tr_loss, label='train loss')\n",
        "    plot.plot(range(nb_epoch), _val_loss, label='val loss')\n",
        "    plot.legend()\n",
        "    plot.grid(True)\n",
        "\n",
        "    plot.subplot(312)\n",
        "    plot.plot(range(nb_epoch), _epoch_metric_loss, label='metric')\n",
        "    plot.plot(range(nb_epoch), _sed_loss[:, 0], label='er')\n",
        "    plot.plot(range(nb_epoch), _sed_loss[:, 1], label='f1')\n",
        "    plot.legend()\n",
        "    plot.grid(True)\n",
        "    \n",
        "    plot.tight_layout()\n",
        "    plot.savefig(fig_name)\n",
        "    plot.close()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    model_dir = params['drive_folder'] + 'models/'\n",
        "    create_folder(model_dir)\n",
        "    unique_name = '{}_ov{}_split{}_{}{}_3d{}_{}'.format(\n",
        "        params['dataset'], params['overlap'], params['split'], params['mode'], params['weakness'],\n",
        "        int(params['cnn_3d']), meta_params['name']\n",
        "    )\n",
        "    unique_name = os.path.join(model_dir, unique_name)\n",
        "    print(\"unique_name: {}\\n\".format(unique_name))\n",
        "\n",
        "    data_gen_train = DataGenerator(\n",
        "        dataset=params['dataset'], ov=params['overlap'], split=params['split'], db=params['db'], nfft=params['nfft'],\n",
        "        batch_size=params['batch_size'], seq_len=meta_params['sequence_length'], classifier_mode=params['mode'],\n",
        "        weakness=params['weakness'], datagen_mode='train', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "        azi_only=params['azi_only']\n",
        "    )\n",
        "\n",
        "    data_gen_test = DataGenerator(\n",
        "        dataset=params['dataset'], ov=params['overlap'], split=params['split'], db=params['db'], nfft=params['nfft'],\n",
        "        batch_size=params['batch_size'], seq_len=meta_params['sequence_length'], classifier_mode=params['mode'],\n",
        "        weakness=params['weakness'], datagen_mode='test', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "        azi_only=params['azi_only'], shuffle=False\n",
        "    )\n",
        "\n",
        "    data_in, data_out = data_gen_train.get_data_sizes()\n",
        "    print(\n",
        "        'FEATURES:\\n'\n",
        "        '\\tdata_in: {}\\n'\n",
        "        '\\tdata_out: {}\\n'.format(\n",
        "            data_in, data_out\n",
        "        )\n",
        "    )\n",
        "\n",
        "    gt = collect_test_labels(data_gen_test, data_out, params['mode'], params['quick_test'])\n",
        "    sed_gt = reshape_3Dto2D(gt[0])\n",
        "    doa_gt = reshape_3Dto2D(gt[1])\n",
        "\n",
        "    print(\n",
        "        'MODEL:\\n'\n",
        "        '\\tdropout_rate: {}\\n'\n",
        "        '\\tCNN: nb_cnn_filt: {}, pool_size{}\\n'\n",
        "        '\\trnn_size: {}, fnn_size: {}\\n'.format(\n",
        "            params['dropout_rate'],\n",
        "            params['nb_cnn3d_filt'] if params['cnn_3d'] else params['nb_cnn2d_filt'], params['pool_size'],\n",
        "            params['rnn_size'], params['fnn_size']\n",
        "        )\n",
        "    )\n",
        "\n",
        "    model = get_model(data_in=data_in, data_out=data_out, dropout_rate=params['dropout_rate'],\n",
        "                                  nb_cnn2d_filt=params['nb_cnn2d_filt'], pool_size=params['pool_size'],\n",
        "                                  rnn_size=params['rnn_size'], fnn_size=params['fnn_size'],\n",
        "                                  classification_mode=params['mode'], weights=params['loss_weights'])\n",
        "    best_metric = 99999\n",
        "    conf_mat = None\n",
        "    best_conf_mat = None\n",
        "    best_epoch = -1\n",
        "    patience_cnt = 0\n",
        "    epoch_metric_loss = np.zeros(params['nb_epochs'])\n",
        "    tr_loss = np.zeros(params['nb_epochs'])\n",
        "    val_loss = np.zeros(params['nb_epochs'])\n",
        "    doa_loss = np.zeros((params['nb_epochs'], 6))\n",
        "    sed_loss = np.zeros((params['nb_epochs'], 2))\n",
        "    nb_epoch = 2 if params['quick_test'] else params['nb_epochs']\n",
        "    for epoch_cnt in range(nb_epoch):\n",
        "        start = time.time()\n",
        "        hist = model.fit_generator(\n",
        "            generator=data_gen_train.generate(),\n",
        "            steps_per_epoch=2 if params['quick_test'] else data_gen_train.get_total_batches_in_data(),\n",
        "            validation_data=data_gen_test.generate(),\n",
        "            validation_steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "            epochs=1,\n",
        "            verbose=1\n",
        "        )\n",
        "        tr_loss[epoch_cnt] = hist.history.get('loss')[-1]\n",
        "        val_loss[epoch_cnt] = hist.history.get('val_loss')[-1]\n",
        "        \n",
        "        \"\"\"\n",
        "        pred = model.predict_generator(\n",
        "            generator=data_gen_test.generate(),\n",
        "            steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        sed_pred = reshape_3Dto2D(pred[0]) > 0.5\n",
        "        doa_pred = reshape_3Dto2D(pred[1])\n",
        "\n",
        "        \n",
        "        print(compute_sed_scores(sed_pred, sed_gt, data_gen_test.nb_frames_1s()))\n",
        "        print(compute_doa_scores_regr_xyz(doa_pred, doa_gt,sed_pred, sed_gt)[0])\n",
        "        \"\"\"\n",
        "        \n",
        "        sed_loss[epoch_cnt, :], doa_loss[epoch_cnt, :] = return_sed_doa_scores(model, gt, data_gen_test)\n",
        "\n",
        "        epoch_metric_loss[epoch_cnt] = np.mean([\n",
        "                sed_loss[epoch_cnt, 0],\n",
        "                1-sed_loss[epoch_cnt, 1],\n",
        "                2*np.arcsin(doa_loss[epoch_cnt, 1]/2.0)/np.pi,\n",
        "                1 - (doa_loss[epoch_cnt, 5] / float(doa_gt.shape[0]))]\n",
        "            )\n",
        "        plot_functions(unique_name, tr_loss, val_loss, sed_loss, doa_loss, epoch_metric_loss)\n",
        "\n",
        "        patience_cnt += 1\n",
        "        if epoch_metric_loss[epoch_cnt] < best_metric:\n",
        "            print(\"Saving\", '{}_model.h5'.format(unique_name), \"with \", epoch_metric_loss[epoch_cnt], \"error\")\n",
        "            best_metric = epoch_metric_loss[epoch_cnt]\n",
        "            best_conf_mat = conf_mat\n",
        "            best_epoch = epoch_cnt\n",
        "            model.save('{}_model.h5'.format(unique_name))\n",
        "            patience_cnt = 0\n",
        "\n",
        "        print(\n",
        "            'epoch_cnt: %d, time: %.2fs, tr_loss: %.2f, val_loss: %.2f, '\n",
        "            'F1_overall: %.2f, ER_overall: %.2f, '\n",
        "            'doa_error_gt: %.2f, doa_error_pred: %.2f, good_pks_ratio:%.2f, '\n",
        "            'error_metric: %.2f, best_error_metric: %.2f, best_epoch : %d' %\n",
        "            (\n",
        "                epoch_cnt, time.time() - start, tr_loss[epoch_cnt], val_loss[epoch_cnt],\n",
        "                sed_loss[epoch_cnt, 1], sed_loss[epoch_cnt, 0],\n",
        "                doa_loss[epoch_cnt, 1], doa_loss[epoch_cnt, 2], doa_loss[epoch_cnt, 5] / float(sed_gt.shape[0]),\n",
        "                epoch_metric_loss[epoch_cnt], best_metric, best_epoch\n",
        "            )\n",
        "        )\n",
        "        if patience_cnt > meta_params['patience']:\n",
        "            break\n",
        "\n",
        "    print('saved model for the best_epoch: {} with best_metric: {},  '.format(best_epoch, best_metric))\n",
        "    print('DOA Metrics: doa_loss_gt: {}, doa_loss_pred: {}, good_pks_ratio: {}'.format(\n",
        "        doa_loss[best_epoch, 1], doa_loss[best_epoch, 2], doa_loss[best_epoch, 5] / float(sed_gt.shape[0])))\n",
        "    print('SED Metrics: ER_overall: {}, F1_overall: {}'.format(sed_loss[best_epoch, 0], sed_loss[best_epoch, 1]))\n",
        "    print('unique_name: {} '.format(unique_name))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EazLeWiLEBST",
        "colab_type": "text"
      },
      "source": [
        "#***Load Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L3BmD-hEGqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models_dir = meta_params['model_dir']\n",
        "\n",
        "def loadmodel(problem):\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\n",
        "    try:\n",
        "        model = load_model(filename)\n",
        "        print(\"\\nModel loaded successfully from file %s\\n\" %filename)\n",
        "    except OSError:    \n",
        "        print(\"\\nModel file %s not found!!!\\n\" %filename)\n",
        "        model = None\n",
        "    return model\n",
        "\n",
        "model = loadmodel('{}_ov{}_split{}_{}{}_3d{}_{}_model'.format(\n",
        "        params['dataset'], params['overlap'], params['split'], params['mode'], params['weakness'],\n",
        "        int(params['cnn_3d']), meta_params['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2idT_ZJtDTGc",
        "colab_type": "text"
      },
      "source": [
        "#***Evaluation***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcg7xL1K7yyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_test_labels(_data_gen_test, _data_out, classification_mode, quick_test):\n",
        "    # Collecting ground truth for test data\n",
        "    nb_batch = 2 if quick_test else _data_gen_test.get_total_batches_in_data()\n",
        "\n",
        "    batch_size = _data_out[0][0]\n",
        "    gt_sed = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[0][2]))\n",
        "    gt_doa = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[1][2]))\n",
        "\n",
        "    print(\"nb_batch in test: {}\".format(nb_batch))\n",
        "    cnt = 0\n",
        "    for tmp_feat, tmp_label in _data_gen_test.generate():\n",
        "        gt_sed[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[0]\n",
        "        gt_doa[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[1]\n",
        "        cnt = cnt + 1\n",
        "        if cnt == nb_batch:\n",
        "            break\n",
        "    return gt_sed.astype(int), gt_doa\n",
        "    \n",
        "def print_generic_evaluation(model, _dataset, _ov, _split):\n",
        "    data_gen_test = DataGenerator(\n",
        "            dataset=_dataset, ov=_ov, split=_split, db=params['db'], nfft=params['nfft'],\n",
        "            batch_size=params['batch_size'], seq_len=meta_params['sequence_length'], classifier_mode=params['mode'],\n",
        "            weakness=params['weakness'], datagen_mode='test', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "            azi_only=params['azi_only'], shuffle=False\n",
        "        )\n",
        "    \n",
        "    values = model.evaluate_generator(data_gen_test.generate(),\n",
        "                                steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "                                verbose = 1)\n",
        "    print(\"Accuracy and Loss evaluation for dataset\", _dataset,\n",
        "          \"ov\", _ov, \"split\", _split)\n",
        "    i = 0\n",
        "    for name in model.metrics_names:\n",
        "        print(name, values[i])\n",
        "        i+=1\n",
        "\n",
        "def print_sed_doa_scores(model, _dataset, _ov, _split):\n",
        "    data_gen_test = DataGenerator(\n",
        "            dataset=_dataset, ov=_ov, split=_split, db=params['db'], nfft=params['nfft'],\n",
        "            batch_size=params['batch_size'], seq_len=meta_params['sequence_length'], classifier_mode=params['mode'],\n",
        "            weakness=params['weakness'], datagen_mode='test', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "            azi_only=params['azi_only'], shuffle=False\n",
        "        )\n",
        "    \n",
        "    data_in, data_out = data_gen_test.get_data_sizes()\n",
        "\n",
        "    nb_batch = 2 if params['quick_test'] else data_gen_test.get_total_batches_in_data()\n",
        "    nb_samples = params['batch_size'] * nb_batch\n",
        "\n",
        "    gt = collect_test_labels(data_gen_test, data_out, params['mode'], params['quick_test'])\n",
        "    sed_gt = reshape_3Dto2D(gt[0])\n",
        "    doa_gt = reshape_3Dto2D(gt[1])\n",
        "\n",
        "    pred = model.predict_generator(\n",
        "                generator=data_gen_test.generate(),\n",
        "                steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "    sed_pred = reshape_3Dto2D(pred[0]) > 0.5\n",
        "    doa_pred = reshape_3Dto2D(pred[1])\n",
        "\n",
        "    sed_scores = compute_sed_scores(sed_pred, sed_gt, data_gen_test.nb_frames_1s())\n",
        "    if params['azi_only']:\n",
        "        doa_scores, conf_mat = compute_doa_scores_regr_xy(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "    else:\n",
        "        doa_scores, conf_mat = compute_doa_scores_regr_xyz(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "        \n",
        "    sed_accuracy = accuracy_score(sed_gt, sed_pred)\n",
        "    doa_variance = explained_variance_score(doa_gt, doa_pred)\n",
        "\n",
        "    print('SED Metrics: ER_overall: {}, F1_overall: {}, accuracy: {}'.format(sed_scores[0], sed_scores[1], sed_accuracy))\n",
        "    print('DOA Metrics: doa_loss_gt: {}, doa_loss_pred: {}, good_pks_ratio: {}, doa_variance: {}'.format(\n",
        "        doa_scores[1], doa_scores[2], doa_scores[5] / float(sed_gt.shape[0]), 1 - doa_variance))\n",
        "    \n",
        "    return sed_scores[0], sed_scores[1], doa_scores[2], doa_scores[5] / float(sed_gt.shape[0]), nb_samples, sed_accuracy, 1 - doa_variance\n",
        " \n",
        "\n",
        "def print_cross_validation_values(model, _dataset, _ov):\n",
        "\n",
        "    error_sp1, f1_score_sp1, error_frame_sp1, frame_recall_sp1, nb_samples_1, sed_accuracy_1, doa_variance_1 = print_sed_doa_scores(model, _dataset, _ov, 1) \n",
        "    error_sp2, f1_score_sp2, error_frame_sp2, frame_recall_sp2, nb_samples_2, sed_accuracy_2, doa_variance_2 = print_sed_doa_scores(model, _dataset, _ov, 2)\n",
        "    error_sp3, f1_score_sp3, error_frame_sp3, frame_recall_sp3, nb_samples_3, sed_accuracy_3, doa_variance_3 = print_sed_doa_scores(model, _dataset, _ov, 3)\n",
        "    \n",
        "    sed_error = np.mean([error_sp1, error_sp2, error_sp3])\n",
        "    f1_score = np.mean([f1_score_sp1, f1_score_sp2, f1_score_sp3])\n",
        "    doa_error = np.mean([error_frame_sp1, error_frame_sp2, error_frame_sp3])\n",
        "    frame_recall = np.mean([frame_recall_sp1, frame_recall_sp2, frame_recall_sp3])\n",
        "    n = nb_samples_1 + nb_samples_2 + nb_samples_3\n",
        "\n",
        "\n",
        "    ############################################################\n",
        "    #calculate mean, standard deviation and confidence intervals\n",
        "    ############################################################\n",
        "    #sed mean accuracy\n",
        "    sed_accuracy = np.mean([sed_accuracy_1, sed_accuracy_2, sed_accuracy_3])\n",
        "    sed_accuracy_error = 1 - sed_accuracy\n",
        "\n",
        "    #doa mean variance\n",
        "    doa_variance = np.mean([doa_variance_1, doa_variance_2, doa_variance_3])\n",
        "\n",
        "    #sed standard deviation\n",
        "    sed_accuracy_crossvalidation_standard_deviation = np.std([sed_accuracy_1, sed_accuracy_2, sed_accuracy_3])\n",
        "    doa_variance_crossvalidation_standard_deviation = np.std([doa_variance_1, doa_variance_2, doa_variance_3])\n",
        "\n",
        "    #confidence intervals #Review error\n",
        "    const = 1.96 ##1.64 (90%) 1.96 (95%) 2.33 (98%) 2.58 (99%) confidence interval\n",
        "    sed_confidence_interval = const * np.sqrt( (sed_accuracy_error * (1 - sed_accuracy_error)) / n) \n",
        "\n",
        "    print('CrossValidation Error : {}, CrossValidation F1_score : {}, CrossValidation Error_frame : {}, CrossValidation Frame_recall : {}'.format(\n",
        "        sed_error, f1_score, doa_error, frame_recall)\n",
        "        )  \n",
        "    print('SED error (confidence interval 95%): {}+/-{}, SED_mean_accuracy: {}, SED_accuracy_crossvalidation_standard_deviation: {}, DOA_mean_variance: {}, DOA_variance_crossvalidation_standard_deviation: {}'.format(\n",
        "        sed_accuracy_error, sed_confidence_interval, sed_accuracy, sed_accuracy_crossvalidation_standard_deviation, doa_variance, doa_variance_crossvalidation_standard_deviation)\n",
        "        )    \n",
        "\n",
        "print_cross_validation_values(model, params['dataset'], params['overlap'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0yqsLBLRqFk",
        "colab_type": "text"
      },
      "source": [
        "#***Check dataset distribution***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr8W5KqlamXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "sys.path.append(os.path.join(sys.path[0], '..'))\n",
        "\n",
        "# Path to the metadata folder\n",
        "base_path = meta_params['base_dir'] + 'desc_ov' + str(params['overlap']) + '_split'\n",
        "dev_dataset = [base_path + '1', base_path + '2', base_path + '3']\n",
        "plot_dir = meta_params['plot_dir'] + 'dataset_distribution/' + meta_params['name'] + '/'\n",
        "\n",
        "create_folder(plot_dir)\n",
        "\n",
        "feat_cls = FeatureClass()\n",
        "hop_len_s = feat_cls.get_hop_len_sec()\n",
        "max_frames = feat_cls.get_nb_frames()\n",
        "unique_classes_dict = feat_cls.get_classes()\n",
        "nb_classes = len(unique_classes_dict)\n",
        "azi_list, ele_list = feat_cls.get_azi_ele_list()\n",
        "min_azi_ind = min(azi_list)//10\n",
        "min_ele_ind = min(ele_list)//10\n",
        "nb_ir = 1 #5\n",
        "nb_files_per_split = [0]*5\n",
        "split_info_dic = {}\n",
        "for dataset_path in dev_dataset:\n",
        "    for file in os.listdir(dataset_path):\n",
        "        desc_dict = feat_cls._read_desc_file(os.path.join(dataset_path, file))\n",
        "        split = int(dataset_path[-1])\n",
        "        ov = int(dataset_path[-8])\n",
        "        nb_files_per_split[split] += 1\n",
        "        if split not in split_info_dic:\n",
        "            split_info_dic[split] = {\n",
        "                'scop': np.zeros(nb_classes),\n",
        "                'length': np.zeros(nb_classes),\n",
        "                'se_cnt': np.zeros(nb_classes),\n",
        "            }\n",
        "\n",
        "        for i, se_class in enumerate(desc_dict['class']):\n",
        "            se_class = unique_classes_dict[se_class]\n",
        "            start = desc_dict['start'][i]\n",
        "            end = desc_dict['end'][i]\n",
        "            split_info_dic[split]['length'][se_class] += (end - start) * hop_len_s\n",
        "            split_info_dic[split]['se_cnt'][se_class] += 1\n",
        "\n",
        "            azi = desc_dict['azi'][i]\n",
        "            ele = desc_dict['ele'][i]\n",
        "\n",
        "cmap = ['b', 'r', 'g', 'y', 'k', 'c', 'm', 'b', 'r', 'g', 'y', 'k', 'c', 'm']\n",
        "azi_list = np.array(azi_list)\n",
        "ele_list = np.array(ele_list)\n",
        "azi_ele_list = np.arange(len(azi_list)*len(ele_list))\n",
        "nb_split = len(split_info_dic.keys())\n",
        "\n",
        "\n",
        "split_list = np.sort(list(split_info_dic))\n",
        "\n",
        "plot.figure(figsize=(10,5))\n",
        "plot.title('Total length of classes', pad = 30)\n",
        "for i in split_list:\n",
        "    plot.bar(np.arange(nb_classes)+0.1*i, split_info_dic[i]['length'], color=cmap[i], width=.15, label='split {}'.format(i))\n",
        "plot.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=nb_split, mode=\"expand\", borderaxespad=0.)\n",
        "plot.ylabel('length in sec')\n",
        "plot.xlabel('Class index')\n",
        "plot.tight_layout()\n",
        "plot.savefig(plot_dir + 'Total_length_of_classes_' + meta_params['name'])\n",
        "\n",
        "\n",
        "plot.figure(figsize = (10,5))\n",
        "plot.title('Number of examples per class', pad = 30)\n",
        "for i in np.sort(list(split_info_dic)):\n",
        "    plot.bar(np.arange(nb_classes)+0.1*i, split_info_dic[i]['se_cnt'], color=cmap[i], width=.15, label='split {}'.format(i))\n",
        "plot.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=nb_split, mode=\"expand\", borderaxespad=0.)\n",
        "plot.ylabel('number of examples/class')\n",
        "plot.xlabel('Class index')\n",
        "plot.tight_layout()\n",
        "plot.savefig(plot_dir + 'Number_of_examples_per_class_' + meta_params['name'])\n",
        "\n",
        "plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNbbGIbIf_1S",
        "colab_type": "text"
      },
      "source": [
        "#***Visualize SELD output***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4rtr1kQZFg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Script for visualising the SELD output.\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plot_dir = meta_params['plot_dir'] + 'SELD_output/' + meta_params['name'] + '/'\n",
        "\n",
        "create_folder(plot_dir)\n",
        "\n",
        "\n",
        "def produce_output(model, _dataset, _ov, _split):\n",
        "    if params['_output']:\n",
        "        _dump_folder = os.path.join(meta_params['results_dir'], '{}_{}_{}'.format(meta_params['name'], params['dataset'], params['mode']))\n",
        "        create_folder(_dump_folder)\n",
        "        print('Dumping recording-wise results in: {}'.format(_dump_folder))\n",
        "\n",
        "        data_gen_test = DataGenerator(\n",
        "            dataset=_dataset, ov=_ov, split=_split, db=params['db'], nfft=params['nfft'],\n",
        "            batch_size=params['batch_size'], seq_len=meta_params['sequence_length'], classifier_mode=params['mode'],\n",
        "            weakness=params['weakness'], datagen_mode='test', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "            azi_only=params['azi_only'], shuffle=False\n",
        "        )\n",
        "\n",
        "        test_filelist = data_gen_test.get_filelist()\n",
        "        # Number of frames for a 60 second audio with 20ms hop length = 3000 frames\n",
        "        max_frames_with_content = data_gen_test.get_nb_frames()\n",
        "\n",
        "        # Number of frames in one batch (batch_size* sequence_length) consists of all the 3000 frames above with\n",
        "        # zero padding in the remaining frames\n",
        "        frames_per_file = data_gen_test.get_frame_per_file()\n",
        "\n",
        "\n",
        "        test_pred = model.predict_generator(\n",
        "            generator=data_gen_test.generate(),\n",
        "            steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        test_sed_pred = reshape_3Dto2D(test_pred[0]) > 0.5\n",
        "        test_doa_pred = reshape_3Dto2D(test_pred[1])\n",
        "\n",
        "\n",
        "        for file_cnt in range(len(test_filelist)):\n",
        "            output_file = os.path.join(_dump_folder, test_filelist[file_cnt].replace('.wav.npy', '.csv'))\n",
        "            dc = file_cnt * frames_per_file\n",
        "            output_dict = regression_label_format_to_output_format(\n",
        "                data_gen_test,\n",
        "                test_sed_pred[dc:dc + max_frames_with_content, :],\n",
        "                test_doa_pred[dc:dc + max_frames_with_content, :] * 180\n",
        "        )\n",
        "            write_output_format_file(output_file, output_dict)\n",
        "\n",
        "def collect_classwise_data(_in_dict):\n",
        "    _out_dict = {}\n",
        "    for _key in _in_dict.keys():\n",
        "        for _seld in _in_dict[_key]:\n",
        "            if _seld[0] not in _out_dict:\n",
        "                _out_dict[_seld[0]] = []\n",
        "            _out_dict[_seld[0]].append([_key, _seld[0], _seld[1], _seld[2], _seld[3]])\n",
        "    return _out_dict\n",
        "\n",
        "\n",
        "def plot_func(plot_data, hop_len_s, ind, plot_x_ax=False):\n",
        "    cmap = ['b', 'r', 'g', 'y', 'k', 'c', 'm', 'b', 'r', 'g', 'y', 'k', 'c', 'm']\n",
        "    for class_ind in plot_data.keys():\n",
        "        time_ax = np.array(plot_data[class_ind])[:, 0] * hop_len_s\n",
        "        y_ax = np.array(plot_data[class_ind])[:, ind]\n",
        "        plot.plot(time_ax, y_ax, marker='.', color=cmap[class_ind], linestyle='None', markersize=4)\n",
        "    plot.grid()\n",
        "    plot.xlim([0, 100])\n",
        "    if not plot_x_ax:\n",
        "        plot.tick_params(\n",
        "            axis='x',  # changes apply to the x-axis\n",
        "            which='both',  # both major and minor ticks are affected\n",
        "            bottom='off',  # ticks along the bottom edge are off\n",
        "            top='off',  # ticks along the top edge are off\n",
        "            labelbottom='off')  # labels along the bottom edge are off\n",
        "\n",
        "\n",
        "# --------------------------------- MAIN SCRIPT STARTS HERE -----------------------------------------\n",
        "\n",
        "produce_output(model, params['dataset'], params['overlap'], 1)\n",
        "# fixed hoplength of 0.02 seconds for evaluation\n",
        "hop_s = 0.02\n",
        "\n",
        "# output format file to visualize\n",
        "out_dir = meta_params['results_dir'] + '{}_{}_{}/'.format(meta_params['name'], params['dataset'], params['mode'])\n",
        "pred_files = os.listdir(out_dir)\n",
        "pred = out_dir + pred_files[0]\n",
        "\n",
        "print('Visualizing output file: {}'.format(pred))\n",
        "\n",
        "# path of reference audio directory for visualizing the description directory for\n",
        "# visualizing the reference\n",
        "ref_dir = meta_params['base_dir'] + 'desc_ov' + str(params['overlap']) + '_split1/'\n",
        "aud_dir = meta_params['base_dir'] + 'wav_ov' + str(params['overlap']) + '_split1_30db'\n",
        "\n",
        "# load the predicted output format\n",
        "pred_dict = load_output_format_file(pred)\n",
        "\n",
        "# load the reference output format\n",
        "feat_cls = FeatureClass()\n",
        "ref_filename = os.path.basename(pred)\n",
        "ref_desc_dict = feat_cls._read_desc_file(os.path.join(ref_dir, ref_filename), norm = True)\n",
        "ref_dict = description_file_to_output_format(ref_desc_dict, feat_cls.get_classes(), hop_s)\n",
        "\n",
        "pred_data = collect_classwise_data(pred_dict)\n",
        "ref_data = collect_classwise_data(ref_dict)\n",
        "\n",
        "nb_classes = len(feat_cls.get_classes())\n",
        "\n",
        "# load the audio and extract spectrogram\n",
        "ref_filename = os.path.basename(pred).replace('.csv', '.wav')\n",
        "audio, fs = feat_cls._load_audio(os.path.join(aud_dir, ref_filename))\n",
        "stft = np.abs(np.squeeze(feat_cls._spectrogram(audio[:, :1])))\n",
        "stft = librosa.amplitude_to_db(stft, ref=np.max)\n",
        "\n",
        "plot.figure(figsize=(10,10))\n",
        "gs = gridspec.GridSpec(4, 4)\n",
        "ax1 = plot.subplot(gs[0, :2]), plot_func(ref_data, hop_s, ind=1), plot.ylim([-1, nb_classes + 1]), plot.title('SED reference')\n",
        "ax2 = plot.subplot(gs[0, 2:]), plot_func(pred_data, hop_s, ind=1), plot.ylim([-1, nb_classes + 1]), plot.title('SED predicted')\n",
        "ax3 = plot.subplot(gs[1, :2]), plot_func(ref_data, hop_s, ind=2), plot.ylim([-190, 190]), plot.title('DOA x reference')\n",
        "ax4 = plot.subplot(gs[1, 2:]), plot_func(pred_data, hop_s, ind=2), plot.ylim([-190, 190]), plot.title('DOA x predicted')\n",
        "ax5 = plot.subplot(gs[2, :2]), plot_func(ref_data, hop_s, ind=3), plot.ylim([-190, 190]), plot.title('DOA y reference')\n",
        "ax6 = plot.subplot(gs[2, 2:]), plot_func(pred_data, hop_s, ind=3), plot.ylim([-190, 190]), plot.title('DOA y predicted')\n",
        "ax7 = plot.subplot(gs[3, :2]), plot_func(ref_data, hop_s, ind=4), plot.ylim([-190, 190]), plot.title('DOA z reference')\n",
        "ax8 = plot.subplot(gs[3, 2:]), plot_func(pred_data, hop_s, ind=4), plot.ylim([-190, 190]), plot.title('DOA z predicted')\n",
        "ax_lst = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n",
        "plot.tight_layout()\n",
        "plot.savefig(plot_dir + meta_params['name'])\n",
        "plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}